"""
Enhanced PE Analysis Module with Textbook-Level Features

Implements comprehensive PE file analysis including:
- Detailed PE header parsing (DOS, COFF, Optional)
- Section characteristics analysis
- Packer detection database (PEiD-style)
- Resource extraction and viewing
- Dependency analysis
- Import/Export detailed analysis
"""

import struct
import logging
from typing import Dict, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class PackerDetector:
    """
    Packer detection database similar to PEiD.
    
    Detects common packers and protectors used to obfuscate malware.
    """
    
    # Signature database for common packers
    PACKER_SIGNATURES = {
        'UPX': {
            'section_names': ['.UPX0', '.UPX1', 'UPX0', 'UPX1'],
            'description': 'UPX - Ultimate Packer for eXecutables',
            'category': 'Packer',
        },
        'ASPack': {
            'section_names': ['.aspack', '.adata', 'ASPack'],
            'description': 'ASPack - Advanced Software Protector',
            'category': 'Packer',
        },
        'PECompact': {
            'section_names': ['PEC2', 'PECompact2'],
            'description': 'PECompact - Compression utility',
            'category': 'Packer',
        },
        'Themida': {
            'section_names': ['.themida', 'Themida'],
            'description': 'Themida - Advanced Windows software protection',
            'category': 'Protector',
        },
        'VMProtect': {
            'section_names': ['.vmp0', '.vmp1', 'vmp0', 'vmp1'],
            'description': 'VMProtect - Software protection system',
            'category': 'Protector',
        },
        'Armadillo': {
            'section_names': ['.arma', 'Armadillo'],
            'description': 'Armadillo - Software protection',
            'category': 'Protector',
        },
        'FSG': {
            'section_names': ['.FSG!'],
            'description': 'FSG - Fast Small Good compressor',
            'category': 'Packer',
        },
        'MEW': {
            'section_names': ['MEW', '.MEW'],
            'description': 'MEW - Morphine Executable Whitener',
            'category': 'Packer',
        },
        'NSPack': {
            'section_names': ['.nsp0', '.nsp1', '.nsp2'],
            'description': 'NSPack - NorthStar PE Compressor',
            'category': 'Packer',
        },
        'Petite': {
            'section_names': ['.petite', 'petite'],
            'description': 'Petite - Win32 PE executable compressor',
            'category': 'Packer',
        },
    }
    
    @classmethod
    def detect_packer(cls, sections: List[Dict], entropy_avg: float = 0) -> Dict:
        """
        Detect packer/protector based on section names and entropy.
        
        Args:
            sections: List of PE sections with names
            entropy_avg: Average entropy of executable sections
        
        Returns:
            Dictionary with detection results
        """
        result = {
            'detected': False,
            'packer_name': None,
            'description': None,
            'category': None,
            'confidence': 'Unknown',
            'indicators': []
        }
        
        if not sections:
            return result
        
        section_names = [s.get('name', '').strip('\x00').upper() for s in sections]
        
        # Check for known packer signatures
        for packer, sig in cls.PACKER_SIGNATURES.items():
            sig_sections = [s.upper() for s in sig['section_names']]
            
            for sec_name in section_names:
                for sig_sec in sig_sections:
                    if sig_sec in sec_name or sec_name in sig_sec:
                        result['detected'] = True
                        result['packer_name'] = packer
                        result['description'] = sig['description']
                        result['category'] = sig['category']
                        result['confidence'] = 'High'
                        result['indicators'].append(f"Section name match: {sec_name}")
                        return result
        
        # Heuristic detection based on entropy and section characteristics
        if entropy_avg > 7.0:
            result['indicators'].append(f"High entropy: {entropy_avg:.2f}")
            
            # Check for typical packer characteristics
            if len(sections) < 3:
                result['indicators'].append("Few sections (typical of packers)")
            
            for section in sections:
                if section.get('virtual_size', 0) > section.get('raw_size', 0) * 2:
                    result['indicators'].append(f"Section {section.get('name')} has large virtual size")
            
            if len(result['indicators']) >= 2:
                result['detected'] = True
                result['packer_name'] = 'Unknown Packer'
                result['description'] = 'Possible packer detected (heuristic)'
                result['category'] = 'Packer (Heuristic)'
                result['confidence'] = 'Medium'
        
        return result


class PEHeaderAnalyzer:
    """
    Detailed PE header analysis including DOS, COFF, and Optional headers.
    """
    
    @staticmethod
    def parse_dos_header(pe_data: bytes) -> Dict:
        """Parse DOS header (IMAGE_DOS_HEADER)."""
        if len(pe_data) < 64:
            return {'error': 'File too small for DOS header'}
        
        try:
            dos_header = {
                'e_magic': struct.unpack('<H', pe_data[0:2])[0],  # MZ signature
                'e_cblp': struct.unpack('<H', pe_data[2:4])[0],
                'e_cp': struct.unpack('<H', pe_data[4:6])[0],
                'e_crlc': struct.unpack('<H', pe_data[6:8])[0],
                'e_cparhdr': struct.unpack('<H', pe_data[8:10])[0],
                'e_minalloc': struct.unpack('<H', pe_data[10:12])[0],
                'e_maxalloc': struct.unpack('<H', pe_data[12:14])[0],
                'e_ss': struct.unpack('<H', pe_data[14:16])[0],
                'e_sp': struct.unpack('<H', pe_data[16:18])[0],
                'e_csum': struct.unpack('<H', pe_data[18:20])[0],
                'e_ip': struct.unpack('<H', pe_data[20:22])[0],
                'e_cs': struct.unpack('<H', pe_data[22:24])[0],
                'e_lfarlc': struct.unpack('<H', pe_data[24:26])[0],
                'e_ovno': struct.unpack('<H', pe_data[26:28])[0],
                'e_lfanew': struct.unpack('<I', pe_data[60:64])[0],  # PE header offset
            }
            
            # Verify MZ signature
            if dos_header['e_magic'] == 0x5A4D:  # 'MZ'
                dos_header['valid'] = True
            else:
                dos_header['valid'] = False
                
            return dos_header
            
        except Exception as e:
            logger.error(f"Error parsing DOS header: {e}")
            return {'error': str(e)}
    
    @staticmethod
    def parse_coff_header(pe_data: bytes, pe_offset: int) -> Dict:
        """Parse COFF File Header (IMAGE_FILE_HEADER)."""
        try:
            offset = pe_offset + 4  # Skip PE signature
            
            machine = struct.unpack('<H', pe_data[offset:offset+2])[0]
            num_sections = struct.unpack('<H', pe_data[offset+2:offset+4])[0]
            timestamp = struct.unpack('<I', pe_data[offset+4:offset+8])[0]
            pointer_to_symbol_table = struct.unpack('<I', pe_data[offset+8:offset+12])[0]
            num_symbols = struct.unpack('<I', pe_data[offset+12:offset+16])[0]
            size_of_optional_header = struct.unpack('<H', pe_data[offset+16:offset+18])[0]
            characteristics = struct.unpack('<H', pe_data[offset+18:offset+20])[0]
            
            # Machine type descriptions
            machine_types = {
                0x0: 'Unknown',
                0x14c: 'Intel 386 (x86)',
                0x8664: 'AMD64 (x64)',
                0x1c0: 'ARM little endian',
                0xaa64: 'ARM64',
                0x200: 'Intel Itanium',
            }
            
            # Characteristics flags
            characteristics_flags = []
            if characteristics & 0x0001:
                characteristics_flags.append('RELOCS_STRIPPED')
            if characteristics & 0x0002:
                characteristics_flags.append('EXECUTABLE_IMAGE')
            if characteristics & 0x0004:
                characteristics_flags.append('LINE_NUMS_STRIPPED')
            if characteristics & 0x0008:
                characteristics_flags.append('LOCAL_SYMS_STRIPPED')
            if characteristics & 0x0020:
                characteristics_flags.append('LARGE_ADDRESS_AWARE')
            if characteristics & 0x0100:
                characteristics_flags.append('32BIT_MACHINE')
            if characteristics & 0x0200:
                characteristics_flags.append('DEBUG_STRIPPED')
            if characteristics & 0x1000:
                characteristics_flags.append('SYSTEM')
            if characteristics & 0x2000:
                characteristics_flags.append('DLL')
            
            return {
                'machine': machine,
                'machine_type': machine_types.get(machine, f'Unknown (0x{machine:x})'),
                'number_of_sections': num_sections,
                'timestamp': timestamp,
                'timestamp_str': datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S') if timestamp > 0 else 'Invalid',
                'pointer_to_symbol_table': pointer_to_symbol_table,
                'number_of_symbols': num_symbols,
                'size_of_optional_header': size_of_optional_header,
                'characteristics': characteristics,
                'characteristics_flags': characteristics_flags,
            }
            
        except Exception as e:
            logger.error(f"Error parsing COFF header: {e}")
            return {'error': str(e)}
    
    @staticmethod
    def parse_optional_header(pe_data: bytes, pe_offset: int, is_64bit: bool = False) -> Dict:
        """Parse Optional Header (IMAGE_OPTIONAL_HEADER)."""
        try:
            offset = pe_offset + 24  # Skip PE signature + COFF header
            
            magic = struct.unpack('<H', pe_data[offset:offset+2])[0]
            
            # PE32 vs PE32+
            is_pe32_plus = magic == 0x20b
            
            result = {
                'magic': hex(magic),
                'type': 'PE32+' if is_pe32_plus else 'PE32',
                'major_linker_version': pe_data[offset+2],
                'minor_linker_version': pe_data[offset+3],
            }
            
            if is_pe32_plus:
                # PE32+ (64-bit)
                result.update({
                    'size_of_code': struct.unpack('<I', pe_data[offset+4:offset+8])[0],
                    'size_of_initialized_data': struct.unpack('<I', pe_data[offset+8:offset+12])[0],
                    'size_of_uninitialized_data': struct.unpack('<I', pe_data[offset+12:offset+16])[0],
                    'address_of_entry_point': struct.unpack('<I', pe_data[offset+16:offset+20])[0],
                    'base_of_code': struct.unpack('<I', pe_data[offset+20:offset+24])[0],
                    'image_base': struct.unpack('<Q', pe_data[offset+24:offset+32])[0],
                })
            else:
                # PE32 (32-bit)
                result.update({
                    'size_of_code': struct.unpack('<I', pe_data[offset+4:offset+8])[0],
                    'size_of_initialized_data': struct.unpack('<I', pe_data[offset+8:offset+12])[0],
                    'size_of_uninitialized_data': struct.unpack('<I', pe_data[offset+12:offset+16])[0],
                    'address_of_entry_point': struct.unpack('<I', pe_data[offset+16:offset+20])[0],
                    'base_of_code': struct.unpack('<I', pe_data[offset+20:offset+24])[0],
                    'base_of_data': struct.unpack('<I', pe_data[offset+24:offset+28])[0],
                    'image_base': struct.unpack('<I', pe_data[offset+28:offset+32])[0],
                })
            
            return result
            
        except Exception as e:
            logger.error(f"Error parsing Optional header: {e}")
            return {'error': str(e)}


class SectionAnalyzer:
    """
    Detailed PE section analysis with characteristics interpretation.
    """
    
    SECTION_CHARACTERISTICS = {
        0x00000020: 'IMAGE_SCN_CNT_CODE',
        0x00000040: 'IMAGE_SCN_CNT_INITIALIZED_DATA',
        0x00000080: 'IMAGE_SCN_CNT_UNINITIALIZED_DATA',
        0x02000000: 'IMAGE_SCN_MEM_DISCARDABLE',
        0x04000000: 'IMAGE_SCN_MEM_NOT_CACHED',
        0x08000000: 'IMAGE_SCN_MEM_NOT_PAGED',
        0x10000000: 'IMAGE_SCN_MEM_SHARED',
        0x20000000: 'IMAGE_SCN_MEM_EXECUTE',
        0x40000000: 'IMAGE_SCN_MEM_READ',
        0x80000000: 'IMAGE_SCN_MEM_WRITE',
    }
    
    @classmethod
    def analyze_section_characteristics(cls, characteristics: int) -> Dict:
        """Parse section characteristics flags."""
        flags = []
        permissions = []
        
        for flag_value, flag_name in cls.SECTION_CHARACTERISTICS.items():
            if characteristics & flag_value:
                flags.append(flag_name)
                
                # Determine permissions
                if flag_value == 0x20000000:  # EXECUTE
                    permissions.append('X')
                elif flag_value == 0x40000000:  # READ
                    permissions.append('R')
                elif flag_value == 0x80000000:  # WRITE
                    permissions.append('W')
        
        return {
            'flags': flags,
            'permissions': ''.join(sorted(permissions)) if permissions else 'None',
            'is_code': 0x00000020 & characteristics != 0,
            'is_data': 0x00000040 & characteristics != 0,
            'is_executable': 0x20000000 & characteristics != 0,
            'is_writable': 0x80000000 & characteristics != 0,
            'is_readable': 0x40000000 & characteristics != 0,
        }
    
    @classmethod
    def get_section_analysis(cls, section: Dict) -> Dict:
        """
        Comprehensive section analysis.
        
        Returns analysis including:
        - Permission analysis
        - Size anomalies
        - Entropy assessment
        - Suspicious characteristics
        """
        analysis = {
            'name': section.get('name', 'Unknown'),
            'suspicious': False,
            'warnings': []
        }
        
        characteristics = section.get('characteristics', 0)
        if isinstance(characteristics, str):
            try:
                characteristics = int(characteristics, 16)
            except:
                characteristics = 0
        
        char_analysis = cls.analyze_section_characteristics(characteristics)
        analysis.update(char_analysis)
        
        # Check for suspicious combinations
        if char_analysis['is_writable'] and char_analysis['is_executable']:
            analysis['suspicious'] = True
            analysis['warnings'].append('WX permissions (writable and executable)')
        
        # Check size anomalies
        virtual_size = section.get('virtual_size', 0)
        raw_size = section.get('raw_size', 0)
        
        if raw_size == 0 and virtual_size > 0:
            analysis['suspicious'] = True
            analysis['warnings'].append('Section has no raw data but has virtual size')
        
        if virtual_size > raw_size * 3:
            analysis['warnings'].append(f'Large virtual size discrepancy (V:{virtual_size} vs R:{raw_size})')
        
        # Check entropy
        entropy = section.get('entropy', 0)
        if entropy > 7.0:
            analysis['warnings'].append(f'High entropy ({entropy:.2f}) - possibly packed/encrypted')
        elif entropy < 1.0 and raw_size > 0:
            analysis['warnings'].append(f'Very low entropy ({entropy:.2f}) - possibly padded/empty')
        
        return analysis


def perform_textbook_analysis(file_path: str) -> Dict:
    """
    Perform comprehensive textbook-level PE analysis.
    
    Implements features from malware analysis textbooks including:
    - Detailed PE header parsing
    - Packer detection
    - Section analysis
    - Characteristics interpretation
    """
    result = {
        'dos_header': {},
        'coff_header': {},
        'optional_header': {},
        'packer_detection': {},
        'section_analysis': [],
        'summary': {}
    }
    
    try:
        with open(file_path, 'rb') as f:
            pe_data = f.read()
        
        # Parse DOS header
        dos_header = PEHeaderAnalyzer.parse_dos_header(pe_data)
        result['dos_header'] = dos_header
        
        if not dos_header.get('valid'):
            result['summary']['error'] = 'Invalid DOS header (not a PE file)'
            return result
        
        pe_offset = dos_header.get('e_lfanew', 0)
        
        # Verify PE signature
        if pe_data[pe_offset:pe_offset+4] != b'PE\0\0':
            result['summary']['error'] = 'Invalid PE signature'
            return result
        
        # Parse COFF header
        coff_header = PEHeaderAnalyzer.parse_coff_header(pe_data, pe_offset)
        result['coff_header'] = coff_header
        
        # Parse Optional header
        is_64bit = coff_header.get('machine', 0) == 0x8664
        optional_header = PEHeaderAnalyzer.parse_optional_header(pe_data, pe_offset, is_64bit)
        result['optional_header'] = optional_header
        
        # If pefile is available, get section details
        try:
            import pefile
            pe = pefile.PE(data=pe_data, fast_load=False)
            
            sections = []
            for section in pe.sections:
                sec_data = {
                    'name': section.Name.decode('utf-8', errors='ignore').strip('\x00'),
                    'virtual_address': section.VirtualAddress,
                    'virtual_size': section.Misc_VirtualSize,
                    'raw_size': section.SizeOfRawData,
                    'entropy': section.get_entropy(),
                    'characteristics': section.Characteristics,
                }
                sections.append(sec_data)
                
                # Analyze section
                sec_analysis = SectionAnalyzer.get_section_analysis(sec_data)
                result['section_analysis'].append(sec_analysis)
            
            # Calculate average entropy for packer detection
            entropies = [s['entropy'] for s in sections if s.get('entropy')]
            avg_entropy = sum(entropies) / len(entropies) if entropies else 0
            
            # Detect packer
            packer_result = PackerDetector.detect_packer(sections, avg_entropy)
            result['packer_detection'] = packer_result
            
            pe.close()
            
        except ImportError:
            result['summary']['note'] = 'Install pefile for detailed section analysis'
        except Exception as e:
            logger.error(f"Error in detailed analysis: {e}")
            result['summary']['analysis_error'] = str(e)
        
        # Create summary
        result['summary'].update({
            'file_type': optional_header.get('type', 'Unknown'),
            'machine_type': coff_header.get('machine_type', 'Unknown'),
            'timestamp': coff_header.get('timestamp_str', 'Unknown'),
            'entry_point': hex(optional_header.get('address_of_entry_point', 0)),
            'is_dll': 'DLL' in coff_header.get('characteristics_flags', []),
            'is_packed': result['packer_detection'].get('detected', False),
        })
        
    except Exception as e:
        logger.error(f"Error in textbook analysis: {e}")
        result['summary']['error'] = str(e)
    
    return result
