"""
MALWARE ANALYSER MODELS

⚠️  CRITICAL SAFETY AND LEGAL NOTICE ⚠️

This module contains STUB/DEMONSTRATION code for malware analysis functionality.
NO ACTUAL MALWARE is created, distributed, or analyzed by this code.

LEGAL WARNINGS:
1. Creating, distributing, or using malware without authorization is ILLEGAL in most jurisdictions
2. Unauthorized computer access is a criminal offense under laws like:
   - Computer Fraud and Abuse Act (CFAA) - USA
   - Computer Misuse Act - UK
   - Council of Europe Convention on Cybercrime - International
3. This code is for EDUCATIONAL PURPOSES ONLY in controlled environments
4. Users are responsible for compliance with all applicable laws and regulations

ETHICAL GUIDELINES:
- Only use in authorized testing environments
- Obtain proper authorization before any security testing
- Never deploy against systems you don't own/have permission to test
- Follow responsible disclosure practices
- Respect privacy and data protection laws

TECHNICAL NOTES:
- All malware detection logic uses STUB implementations
- All malware generation logic uses STUB implementations
- Test artifacts created are benign demonstration files only
- Production use requires integration with real security tools
"""

from django.db import models
from django.contrib.auth.models import User
from django.core.validators import FileExtensionValidator
from django.utils import timezone
import uuid
import hashlib


class MalwareSignature(models.Model):
    """
    Model for storing malware signatures used in signature-based detection.
    
    STUB IMPLEMENTATION: In production, this would integrate with malware
    signature databases like YARA rules, ClamAV signatures, or custom patterns.
    
    Security: This is demonstration code only. Real signatures would come from
    trusted threat intelligence sources.
    """
    name = models.CharField(max_length=255, help_text="Name of the malware signature")
    signature_type = models.CharField(
        max_length=50,
        choices=[
            ('hash', 'File Hash'),
            ('pattern', 'Byte Pattern'),
            ('yara', 'YARA Rule'),
            ('behavior', 'Behavioral Signature'),
        ],
        default='hash'
    )
    signature_data = models.TextField(help_text="Signature data (hash, pattern, or rule)")
    severity = models.CharField(
        max_length=20,
        choices=[
            ('low', 'Low'),
            ('medium', 'Medium'),
            ('high', 'High'),
            ('critical', 'Critical'),
        ],
        default='medium'
    )
    description = models.TextField(blank=True)
    malware_family = models.CharField(max_length=255, blank=True, help_text="Known malware family")
    is_active = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)
    created_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True, related_name='signatures')
    
    class Meta:
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['signature_type', 'is_active']),
        ]
    
    def __str__(self):
        return f"{self.name} ({self.get_signature_type_display()})"


class FileUpload(models.Model):
    """
    Model for storing uploaded files for malware scanning.
    
    ACCEPTS ALL FILE TYPES as per requirements.
    
    Security Notes:
    - Files stored with UUID names to prevent path traversal
    - Original filenames sanitized
    - Access control enforced
    - Scan status tracked
    """
    file_id = models.UUIDField(default=uuid.uuid4, editable=False, unique=True, primary_key=True)
    original_filename = models.CharField(max_length=500)
    file = models.FileField(upload_to='malware_analyser_uploads/')
    file_size = models.BigIntegerField(help_text="File size in bytes")
    file_hash_md5 = models.CharField(max_length=32, blank=True)
    file_hash_sha256 = models.CharField(max_length=64, blank=True)
    mime_type = models.CharField(max_length=255, blank=True)
    uploaded_by = models.ForeignKey(User, on_delete=models.CASCADE, related_name='uploaded_files')
    uploaded_at = models.DateTimeField(auto_now_add=True)
    is_scanned = models.BooleanField(default=False)
    scan_status = models.CharField(
        max_length=20,
        choices=[
            ('pending', 'Pending Scan'),
            ('scanning', 'Scanning'),
            ('clean', 'Clean'),
            ('infected', 'Infected'),
            ('error', 'Scan Error'),
        ],
        default='pending'
    )
    
    class Meta:
        ordering = ['-uploaded_at']
        indexes = [
            models.Index(fields=['uploaded_by', 'uploaded_at']),
            models.Index(fields=['scan_status']),
            models.Index(fields=['file_hash_sha256']),
        ]
    
    def __str__(self):
        return f"{self.original_filename} - {self.scan_status}"
    
    def calculate_hashes(self):
        """Calculate file hashes for signature matching (STUB)."""
        # STUB: In production, this would read the actual file
        # For now, we generate a pseudo-hash based on filename and size
        content = f"{self.original_filename}{self.file_size}".encode()
        self.file_hash_md5 = hashlib.md5(content).hexdigest()
        self.file_hash_sha256 = hashlib.sha256(content).hexdigest()
        self.save()


class ScanResult(models.Model):
    """
    Model for storing scan results.
    
    STUB IMPLEMENTATION: Real scanning would integrate with:
    - ClamAV or similar antivirus engines
    - YARA rule matching
    - Sandboxing systems (Cuckoo, ANY.RUN)
    - Behavioral analysis tools
    - Threat intelligence platforms
    """
    scan_id = models.UUIDField(default=uuid.uuid4, editable=False, unique=True)
    file = models.ForeignKey(FileUpload, on_delete=models.CASCADE, related_name='scan_results')
    scan_type = models.CharField(
        max_length=50,
        choices=[
            ('signature', 'Signature-based'),
            ('heuristic', 'Heuristic'),
            ('behavioral', 'Behavioral'),
            ('full', 'Full Scan'),
        ],
        default='full'
    )
    started_at = models.DateTimeField(auto_now_add=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    is_malicious = models.BooleanField(default=False)
    threat_level = models.CharField(
        max_length=20,
        choices=[
            ('none', 'No Threat'),
            ('low', 'Low'),
            ('medium', 'Medium'),
            ('high', 'High'),
            ('critical', 'Critical'),
        ],
        default='none'
    )
    detected_malware = models.CharField(max_length=255, blank=True, help_text="Name of detected malware")
    matched_signatures = models.ManyToManyField(MalwareSignature, blank=True, related_name='scan_results')
    scan_details = models.JSONField(default=dict, blank=True, help_text="Detailed scan information")
    performed_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True, related_name='scans')
    
    class Meta:
        ordering = ['-started_at']
        indexes = [
            models.Index(fields=['file', 'started_at']),
            models.Index(fields=['is_malicious']),
        ]
    
    def __str__(self):
        return f"Scan {self.scan_id} - {self.file.original_filename} ({'Malicious' if self.is_malicious else 'Clean'})"


class CleaningLog(models.Model):
    """
    Model for tracking malware cleaning/removal operations.
    
    STUB IMPLEMENTATION: Real cleaning would involve:
    - Quarantine procedures
    - Safe file deletion
    - Registry cleaning (Windows)
    - Process termination
    - System restoration
    
    Security: In production, cleaning operations must be carefully designed
    to avoid system damage or data loss.
    """
    cleaning_id = models.UUIDField(default=uuid.uuid4, editable=False, unique=True)
    scan_result = models.ForeignKey(ScanResult, on_delete=models.CASCADE, related_name='cleaning_logs')
    file = models.ForeignKey(FileUpload, on_delete=models.CASCADE, related_name='cleaning_logs')
    cleaning_action = models.CharField(
        max_length=50,
        choices=[
            ('quarantine', 'Quarantine'),
            ('delete', 'Delete'),
            ('clean', 'Clean/Disinfect'),
            ('restore', 'Restore from Quarantine'),
        ],
        default='quarantine'
    )
    performed_at = models.DateTimeField(auto_now_add=True)
    performed_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True, related_name='cleaning_actions')
    success = models.BooleanField(default=False)
    action_details = models.TextField(blank=True, help_text="Details of cleaning action performed")
    backup_location = models.CharField(max_length=500, blank=True, help_text="Backup/quarantine location")
    
    class Meta:
        ordering = ['-performed_at']
    
    def __str__(self):
        status = "Success" if self.success else "Failed"
        return f"{self.get_cleaning_action_display()} - {self.file.original_filename} ({status})"


class TestMalwareArtifact(models.Model):
    """
    Model for tracking TEST malware artifacts created for safe testing.
    
    ⚠️  CRITICAL WARNING ⚠️
    This functionality is RESTRICTED to authorized staff/superusers only.
    
    LEGAL AND ETHICAL REQUIREMENTS:
    1. Only use in isolated, authorized testing environments
    2. Never distribute outside controlled environment
    3. Obtain proper authorization before creation
    4. Follow organizational security policies
    5. Document all usage for audit purposes
    
    STUB IMPLEMENTATION: This creates benign demonstration files only.
    Real implementation would require:
    - Air-gapped/isolated systems
    - Comprehensive audit logging
    - Secure storage with encryption
    - Access control and MFA
    - Legal review and approval
    - Compliance with applicable laws
    
    NO ACTUAL MALWARE IS CREATED BY THIS STUB CODE.
    """
    artifact_id = models.UUIDField(default=uuid.uuid4, editable=False, unique=True, primary_key=True)
    name = models.CharField(max_length=255, help_text="Name of the test artifact")
    artifact_type = models.CharField(
        max_length=50,
        choices=[
            ('benign_test', 'Benign Test File'),
            ('eicar_test', 'EICAR Test String'),
            ('custom_pattern', 'Custom Pattern Test'),
        ],
        default='benign_test',
        help_text="Type of test artifact (STUB - all are benign)"
    )
    description = models.TextField(help_text="Description of the test artifact and its purpose")
    file_content = models.TextField(blank=True, help_text="Content of the test artifact (if text-based)")
    file_path = models.CharField(max_length=500, blank=True, help_text="Path to stored test file")
    created_at = models.DateTimeField(auto_now_add=True)
    created_by = models.ForeignKey(
        User, 
        on_delete=models.SET_NULL, 
        null=True, 
        related_name='test_artifacts',
        help_text="MUST be staff/superuser"
    )
    purpose = models.TextField(help_text="Documented purpose for creating this test artifact")
    authorization_reference = models.CharField(
        max_length=255, 
        blank=True,
        help_text="Reference to authorization/approval"
    )
    is_active = models.BooleanField(default=True)
    destroyed_at = models.DateTimeField(null=True, blank=True, help_text="When artifact was safely destroyed")
    
    class Meta:
        ordering = ['-created_at']
        permissions = [
            ('can_create_test_malware', 'Can create test malware artifacts'),
        ]
    
    def __str__(self):
        return f"Test Artifact: {self.name} (Created: {self.created_at.strftime('%Y-%m-%d')})"
    
    def generate_eicar_test(self):
        """
        Generate the standard EICAR test string.
        
        The EICAR test file is an industry-standard, non-malicious test file
        recognized by antivirus software. It is safe and legal to use for testing.
        
        Reference: https://www.eicar.org/download-anti-malware-testfile/
        """
        # EICAR Standard Anti-Virus Test File
        self.file_content = r'X5O!P%@AP[4\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*'
        self.artifact_type = 'eicar_test'
        self.save()
    
    def generate_benign_test(self):
        """Generate a benign test file for testing purposes (STUB)."""
        self.file_content = f"BENIGN TEST FILE\nCreated: {timezone.now()}\nPurpose: {self.purpose}"
        self.artifact_type = 'benign_test'
        self.save()


class AuditLog(models.Model):
    """
    Comprehensive audit logging for all malware analyser operations.
    
    Critical for:
    - Security incident response
    - Compliance requirements
    - Forensic analysis
    - Access control verification
    """
    log_id = models.UUIDField(default=uuid.uuid4, editable=False, unique=True)
    timestamp = models.DateTimeField(auto_now_add=True)
    user = models.ForeignKey(User, on_delete=models.SET_NULL, null=True, blank=True)
    action = models.CharField(max_length=100)
    resource_type = models.CharField(max_length=50)
    resource_id = models.CharField(max_length=100, blank=True)
    ip_address = models.GenericIPAddressField(null=True, blank=True)
    user_agent = models.CharField(max_length=500, blank=True)
    details = models.JSONField(default=dict, blank=True)
    success = models.BooleanField(default=True)
    error_message = models.TextField(blank=True)
    
    class Meta:
        ordering = ['-timestamp']
        indexes = [
            models.Index(fields=['user', 'timestamp']),
            models.Index(fields=['action', 'timestamp']),
            models.Index(fields=['resource_type', 'resource_id']),
        ]
    
    def __str__(self):
        return f"{self.action} by {self.user} at {self.timestamp}"
