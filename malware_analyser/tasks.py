"""
Celery tasks for asynchronous malware analysis pipeline.

STUB IMPLEMENTATION - All task logic uses demonstration code only.
No actual malware is analyzed. See models.py for full legal/ethical notices.
"""

import logging
import time
from typing import Any, Dict, List

from celery import shared_task

logger = logging.getLogger(__name__)


def _get_file_upload(file_id: str):
    """Retrieve a FileUpload instance, raising ValueError if not found."""
    from malware_analyser.models import FileUpload
    try:
        return FileUpload.objects.get(file_id=file_id)
    except FileUpload.DoesNotExist as exc:
        raise ValueError(f"FileUpload {file_id!r} not found") from exc


def _update(self, state: str, progress: int, stage: str) -> None:
    """Convenience wrapper around self.update_state."""
    self.update_state(
        state=state,
        meta={"progress": progress, "stage": stage},
    )


# ---------------------------------------------------------------------------
# Full analysis pipeline
# ---------------------------------------------------------------------------

@shared_task(bind=True, max_retries=3, name="malware_analyser.tasks.async_full_analysis")
def async_full_analysis(self, file_id: str) -> Dict[str, Any]:
    """
    Orchestrate the complete malware analysis pipeline for a given file.

    Stages (with progress %):
      5%   – hash calculation
      15%  – format detection
      25%  – static YARA scan
      40%  – ML classification
      55%  – sandbox execution
      70%  – config extraction
      80%  – threat intel lookup
      90%  – IOC export
      100% – report generation

    Args:
        file_id: UUID string of the :class:`malware_analyser.models.FileUpload`.

    Returns:
        dict with keys ``status``, ``result``, and ``error``.
    """
    try:
        file_obj = _get_file_upload(file_id)

        # ── Stage 1: hash calculation ────────────────────────────────────────
        _update(self, "PROGRESS", 5, "hash_calculation")
        logger.info("[%s] Calculating hashes for %s", file_id, file_obj.original_filename)
        file_obj.calculate_hashes()

        # ── Stage 2: format detection ────────────────────────────────────────
        _update(self, "PROGRESS", 15, "format_detection")
        logger.info("[%s] Detecting file format", file_id)
        # STUB: mime type already stored at upload time
        detected_format = file_obj.mime_type or "application/octet-stream"

        # ── Stage 3: static YARA scan ────────────────────────────────────────
        _update(self, "PROGRESS", 25, "yara_scan")
        logger.info("[%s] Running YARA scan", file_id)
        yara_result = _run_yara_stub(file_obj)

        # ── Stage 4: ML classification ───────────────────────────────────────
        _update(self, "PROGRESS", 40, "ml_classification")
        logger.info("[%s] Running ML classification", file_id)
        ml_result = _run_ml_stub(file_obj)

        # ── Stage 5: sandbox execution ───────────────────────────────────────
        _update(self, "PROGRESS", 55, "sandbox_execution")
        logger.info("[%s] Submitting to sandbox", file_id)
        sandbox_result = _run_sandbox_stub(file_obj)

        # ── Stage 6: config extraction ───────────────────────────────────────
        _update(self, "PROGRESS", 70, "config_extraction")
        logger.info("[%s] Extracting malware config", file_id)
        config_result = _extract_config_stub(file_obj)

        # ── Stage 7: threat intel lookup ─────────────────────────────────────
        _update(self, "PROGRESS", 80, "threat_intel")
        logger.info("[%s] Querying threat intelligence", file_id)
        intel_result = _threat_intel_stub([file_obj.file_hash_md5, file_obj.file_hash_sha256])

        # ── Stage 8: IOC export ──────────────────────────────────────────────
        _update(self, "PROGRESS", 90, "ioc_export")
        logger.info("[%s] Exporting IOCs", file_id)
        ioc_result = _export_iocs_stub(file_obj)

        # ── Stage 9: report generation ───────────────────────────────────────
        _update(self, "PROGRESS", 95, "report_generation")
        logger.info("[%s] Generating analysis report", file_id)
        _generate_report_stub(file_obj)

        # ── Mark file as scanned ─────────────────────────────────────────────
        file_obj.is_scanned = True
        file_obj.scan_status = "clean"
        file_obj.save(update_fields=["is_scanned", "scan_status"])

        summary = {
            "file_id": str(file_id),
            "filename": file_obj.original_filename,
            "md5": file_obj.file_hash_md5,
            "sha256": file_obj.file_hash_sha256,
            "detected_format": detected_format,
            "yara": yara_result,
            "ml": ml_result,
            "sandbox": sandbox_result,
            "config": config_result,
            "threat_intel": intel_result,
            "iocs": ioc_result,
        }
        _update(self, "SUCCESS", 100, "complete")
        return {"status": "success", "result": summary, "error": None}

    except ValueError as exc:
        logger.error("[%s] File not found: %s", file_id, exc)
        return {"status": "error", "result": None, "error": str(exc)}
    except Exception as exc:  # noqa: BLE001
        logger.exception("[%s] Unexpected error during full analysis", file_id)
        try:
            raise self.retry(exc=exc, countdown=30)
        except self.MaxRetriesExceededError:
            return {"status": "error", "result": None, "error": str(exc)}


# ---------------------------------------------------------------------------
# YARA-only scan
# ---------------------------------------------------------------------------

@shared_task(bind=True, max_retries=3, name="malware_analyser.tasks.async_yara_scan")
def async_yara_scan(self, file_id: str) -> Dict[str, Any]:
    """
    Run YARA scanning only for a given file.

    Args:
        file_id: UUID string of the FileUpload.

    Returns:
        dict with keys ``status``, ``result``, and ``error``.
    """
    try:
        file_obj = _get_file_upload(file_id)
        _update(self, "PROGRESS", 10, "yara_initialising")
        logger.info("[%s] Starting YARA-only scan for %s", file_id, file_obj.original_filename)

        _update(self, "PROGRESS", 50, "yara_scanning")
        result = _run_yara_stub(file_obj)

        _update(self, "SUCCESS", 100, "yara_complete")
        return {"status": "success", "result": result, "error": None}

    except ValueError as exc:
        logger.error("[%s] %s", file_id, exc)
        return {"status": "error", "result": None, "error": str(exc)}
    except Exception as exc:  # noqa: BLE001
        logger.exception("[%s] YARA scan failed", file_id)
        try:
            raise self.retry(exc=exc, countdown=15)
        except self.MaxRetriesExceededError:
            return {"status": "error", "result": None, "error": str(exc)}


# ---------------------------------------------------------------------------
# Sandbox submission
# ---------------------------------------------------------------------------

@shared_task(bind=True, max_retries=3, name="malware_analyser.tasks.async_sandbox_submit")
def async_sandbox_submit(self, file_id: str, sandbox_type: str = "docker") -> Dict[str, Any]:
    """
    Submit a file to a sandbox and poll until completion.

    Args:
        file_id: UUID string of the FileUpload.
        sandbox_type: Type of sandbox backend (e.g. ``'docker'``, ``'vm'``).

    Returns:
        dict with keys ``status``, ``result``, and ``error``.
    """
    try:
        file_obj = _get_file_upload(file_id)
        logger.info("[%s] Submitting to %s sandbox", file_id, sandbox_type)

        _update(self, "PROGRESS", 10, "sandbox_submitting")
        # STUB: simulate submission
        submission_id = f"stub-{file_id[:8]}"

        # STUB: simulate polling
        for tick, pct in enumerate([30, 50, 70, 90], start=1):
            _update(self, "PROGRESS", pct, f"sandbox_polling_{tick}")
            time.sleep(0)  # replaced with real polling in production

        result = _run_sandbox_stub(file_obj, sandbox_type=sandbox_type)
        result["submission_id"] = submission_id

        _update(self, "SUCCESS", 100, "sandbox_complete")
        return {"status": "success", "result": result, "error": None}

    except ValueError as exc:
        logger.error("[%s] %s", file_id, exc)
        return {"status": "error", "result": None, "error": str(exc)}
    except Exception as exc:  # noqa: BLE001
        logger.exception("[%s] Sandbox submission failed", file_id)
        try:
            raise self.retry(exc=exc, countdown=60)
        except self.MaxRetriesExceededError:
            return {"status": "error", "result": None, "error": str(exc)}


# ---------------------------------------------------------------------------
# Batch threat intel lookup
# ---------------------------------------------------------------------------

@shared_task(bind=True, max_retries=3, name="malware_analyser.tasks.async_threat_intel_lookup")
def async_threat_intel_lookup(self, hashes: List[str]) -> Dict[str, Any]:
    """
    Perform batch threat intelligence lookups for a list of hashes.

    Args:
        hashes: List of MD5/SHA-256 hash strings to look up.

    Returns:
        dict with keys ``status``, ``result``, and ``error``.
    """
    try:
        total = len(hashes)
        if total == 0:
            return {"status": "success", "result": {}, "error": None}

        results: Dict[str, Any] = {}
        for idx, h in enumerate(hashes):
            progress = int((idx / total) * 90) + 5
            _update(self, "PROGRESS", progress, f"lookup_{idx + 1}_of_{total}")
            results[h] = _threat_intel_stub([h])

        _update(self, "SUCCESS", 100, "threat_intel_complete")
        return {"status": "success", "result": results, "error": None}

    except Exception as exc:  # noqa: BLE001
        logger.exception("Threat intel batch lookup failed")
        try:
            raise self.retry(exc=exc, countdown=20)
        except self.MaxRetriesExceededError:
            return {"status": "error", "result": None, "error": str(exc)}


# ---------------------------------------------------------------------------
# Private stub helpers (STUB implementations – replace with real logic)
# ---------------------------------------------------------------------------

def _run_yara_stub(file_obj) -> Dict[str, Any]:
    """STUB: Return placeholder YARA scan result."""
    return {
        "matched_rules": [],
        "scanned": True,
        "engine": "yara-stub",
    }


def _run_ml_stub(file_obj) -> Dict[str, Any]:
    """STUB: Return placeholder ML classification result."""
    return {
        "classification": "unknown",
        "confidence": 0.0,
        "engine": "ml-stub",
    }


def _run_sandbox_stub(file_obj, sandbox_type: str = "docker") -> Dict[str, Any]:
    """STUB: Return placeholder sandbox execution result."""
    return {
        "sandbox_type": sandbox_type,
        "status": "completed",
        "behaviours": [],
        "network_connections": [],
    }


def _extract_config_stub(file_obj) -> Dict[str, Any]:
    """STUB: Return placeholder malware config extraction result."""
    return {
        "c2_servers": [],
        "mutex": [],
        "registry_keys": [],
        "extracted": False,
    }


def _threat_intel_stub(hashes: List[str]) -> Dict[str, Any]:
    """STUB: Return placeholder threat intel lookup result."""
    return {
        "hashes_queried": hashes,
        "malicious": False,
        "vendor_detections": {},
        "source": "stub",
    }


def _export_iocs_stub(file_obj) -> Dict[str, Any]:
    """STUB: Return placeholder IOC export result."""
    return {
        "domains": [],
        "ips": [],
        "urls": [],
        "hashes": [file_obj.file_hash_md5, file_obj.file_hash_sha256],
    }


def _generate_report_stub(file_obj) -> None:
    """STUB: Placeholder for report generation; no-op in demo mode."""
    logger.debug("Report generation stub called for %s", file_obj.original_filename)
