"""
MALWARE ANALYSER VIEWS

⚠️  CRITICAL SAFETY AND LEGAL NOTICE ⚠️

This module integrates with ClamAV for REAL malware detection.
This is for EDUCATIONAL/DEMONSTRATION purposes only.

LEGAL WARNINGS:
- Use only in authorized, controlled testing environments
- Never analyze real malware outside secure sandboxes
- Follow all applicable laws and regulations
- This is NOT for production malware analysis

See models.py for comprehensive legal warnings and ethical guidelines.
"""

from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.decorators import login_required, user_passes_test
from django.views.decorators.http import require_http_methods
from django.http import JsonResponse, HttpResponse
from django.contrib import messages
from django.utils.html import escape
from django.utils import timezone
from django.core.exceptions import PermissionDenied
from django.db import transaction
import mimetypes
import logging

from .models import (
    MalwareSignature, FileUpload, ScanResult, 
    CleaningLog, TestMalwareArtifact, AuditLog
)
from .forms import (
    FileUploadForm, TestMalwareCreationForm, MalwareSignatureForm
)
from .clamav_scanner import get_clamav_scanner

logger = logging.getLogger(__name__)


def get_client_ip(request):
    """Extract client IP address from request."""
    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
    if x_forwarded_for:
        ip = x_forwarded_for.split(',')[0]
    else:
        ip = request.META.get('REMOTE_ADDR', '127.0.0.1')
    return ip


def log_action(request, action, resource_type, resource_id='', success=True, error_message='', details=None):
    """Helper function to log actions to audit log."""
    AuditLog.objects.create(
        user=request.user if request.user.is_authenticated else None,
        action=action,
        resource_type=resource_type,
        resource_id=str(resource_id),
        ip_address=get_client_ip(request),
        user_agent=request.META.get('HTTP_USER_AGENT', '')[:500],
        details=details or {},
        success=success,
        error_message=error_message
    )


@login_required
def dashboard(request):
    """
    Main dashboard for Malware Analyser with ADVANCED ANALYTICS.
    Shows recent uploads, scans, and comprehensive statistics.
    """
    from .visualization import generate_detection_summary
    
    recent_uploads = FileUpload.objects.filter(uploaded_by=request.user).order_by('-uploaded_at')[:10]
    recent_scans = ScanResult.objects.filter(performed_by=request.user).order_by('-started_at')[:10]
    
    # Basic Statistics
    total_uploads = FileUpload.objects.filter(uploaded_by=request.user).count()
    total_scans = ScanResult.objects.filter(performed_by=request.user).count()
    infected_files = ScanResult.objects.filter(performed_by=request.user, is_malicious=True).count()
    clean_files = ScanResult.objects.filter(performed_by=request.user, is_malicious=False).count()
    
    # ⭐ ADVANCED STATISTICS ⭐
    # Detection method breakdown
    yara_detections = 0
    ml_detections = 0
    signature_detections = 0
    pe_analyzed = 0
    
    for scan in recent_scans:
        if hasattr(scan, 'static_analysis'):
            static = scan.static_analysis
            if static.yara_matches:
                yara_detections += 1
            if static.pe_data and static.pe_data.get('is_pe'):
                pe_analyzed += 1
        
        if scan.scan_details.get('ml_prediction', {}).get('is_malicious'):
            ml_detections += 1
        
        if scan.matched_signatures.exists():
            signature_detections += 1
    
    # Threat level distribution
    threat_distribution = {
        'critical': ScanResult.objects.filter(performed_by=request.user, threat_level='critical').count(),
        'high': ScanResult.objects.filter(performed_by=request.user, threat_level='high').count(),
        'medium': ScanResult.objects.filter(performed_by=request.user, threat_level='medium').count(),
        'low': ScanResult.objects.filter(performed_by=request.user, threat_level='low').count(),
    }
    
    # Recent detections with details
    recent_detections = []
    for scan in recent_scans[:5]:
        if scan.is_malicious:
            detection_methods = []
            if hasattr(scan, 'static_analysis') and scan.static_analysis.yara_matches:
                detection_methods.append('YARA')
            if scan.scan_details.get('ml_prediction', {}).get('is_malicious'):
                detection_methods.append('ML')
            if scan.matched_signatures.exists():
                detection_methods.append('Signature')
            
            recent_detections.append({
                'scan': scan,
                'methods': ', '.join(detection_methods) if detection_methods else 'Heuristic'
            })
    
    context = {
        'recent_uploads': recent_uploads,
        'recent_scans': recent_scans,
        'total_uploads': total_uploads,
        'total_scans': total_scans,
        'infected_files': infected_files,
        'clean_files': clean_files,
        # Advanced stats
        'yara_detections': yara_detections,
        'ml_detections': ml_detections,
        'signature_detections': signature_detections,
        'pe_analyzed': pe_analyzed,
        'threat_distribution': threat_distribution,
        'recent_detections': recent_detections,
        'detection_rate': (infected_files / total_scans * 100) if total_scans > 0 else 0,
    }
    
    log_action(request, 'view_dashboard', 'dashboard')
    return render(request, 'malware_analyser/dashboard.html', context)


@login_required
@require_http_methods(["GET", "POST"])
def upload_file(request):
    """
    Handle file upload for malware scanning.
    ACCEPTS ALL FILE TYPES as per requirements.
    """
    if request.method == 'POST':
        form = FileUploadForm(request.POST, request.FILES)
        if form.is_valid():
            try:
                uploaded_file = request.FILES['file']
                
                # Sanitize filename
                sanitized_filename = escape(uploaded_file.name)
                
                # Detect MIME type
                mime_type, _ = mimetypes.guess_type(uploaded_file.name)
                if not mime_type:
                    mime_type = 'application/octet-stream'
                
                # Create file upload record
                file_upload = FileUpload(
                    original_filename=sanitized_filename,
                    file=uploaded_file,
                    file_size=uploaded_file.size,
                    mime_type=mime_type,
                    uploaded_by=request.user
                )
                file_upload.save()
                
                # Calculate hashes (STUB)
                file_upload.calculate_hashes()
                
                log_action(
                    request, 
                    'file_upload', 
                    'file', 
                    file_upload.file_id,
                    details={'filename': sanitized_filename, 'size': uploaded_file.size}
                )
                
                messages.success(request, f'File "{sanitized_filename}" uploaded successfully. Redirecting to scan...')
                return redirect('malware_analyser:scan_file', file_id=file_upload.file_id)
                
            except Exception as e:
                error_msg = f'Error uploading file: {str(e)}'
                log_action(request, 'file_upload', 'file', success=False, error_message=error_msg)
                messages.error(request, error_msg)
        else:
            messages.error(request, 'Invalid form data. Please check your upload.')
    else:
        form = FileUploadForm()
    
    return render(request, 'malware_analyser/upload.html', {'form': form})


@login_required
def scan_file(request, file_id):
    """
    Perform malware scan on uploaded file using ClamAV.
    
    REAL SCANNING with ClamAV antivirus engine.
    Falls back to stub implementation if ClamAV is unavailable.
    
    ⚠️  FOR EDUCATIONAL USE ONLY - Use in controlled environments ⚠️
    """
    file_upload = get_object_or_404(FileUpload, file_id=file_id)
    
    # Check permissions
    if file_upload.uploaded_by != request.user and not request.user.is_staff:
        log_action(request, 'scan_file', 'file', file_id, success=False, error_message='Unauthorized access')
        raise PermissionDenied("You don't have permission to scan this file.")
    
    # Check ClamAV availability for display
    scanner = get_clamav_scanner()
    clamav_available = scanner.is_available()
    clamav_version = scanner.get_version() if clamav_available else None
    
    if request.method == 'POST':
        scan_type = request.POST.get('scan_type', 'full')
        
        # Create scan result
        scan_result = ScanResult.objects.create(
            file=file_upload,
            scan_type=scan_type,
            performed_by=request.user
        )
        
        # Perform ClamAV scan first if available
        if clamav_available:
            perform_clamav_scan(scan_result, file_upload)
        else:
            # Log warning that ClamAV is not available
            logger.warning("ClamAV not available, using stub scanning")
            scan_result.scan_details['clamav_unavailable'] = True
            scan_result.scan_details['warning'] = 'ClamAV daemon not available, using basic detection only'
        
        # Also perform signature-based scanning (stub or database signatures)
        if scan_type in ['signature', 'full']:
            perform_signature_scan(scan_result, file_upload)
        
        # Perform heuristic scanning (stub)
        if scan_type in ['heuristic', 'full']:
            perform_heuristic_scan(scan_result, file_upload)
        
        # Mark as completed
        scan_result.completed_at = timezone.now()
        scan_result.save()
        
        # Update file upload status
        file_upload.is_scanned = True
        file_upload.scan_status = 'infected' if scan_result.is_malicious else 'clean'
        file_upload.save()
        
        log_action(
            request, 
            'scan_completed', 
            'scan', 
            scan_result.scan_id,
            details={
                'file_id': str(file_id),
                'scan_type': scan_type,
                'is_malicious': scan_result.is_malicious,
                'clamav_used': clamav_available
            }
        )
        
        if scan_result.is_malicious:
            # Escape malware name to prevent XSS
            malware_name = escape(scan_result.detected_malware or "unknown threat")
            messages.warning(request, f'⚠️ MALWARE DETECTED: File is INFECTED with {malware_name}')
        else:
            messages.success(request, '✓ Scan completed. File is CLEAN.')
        
        if not clamav_available:
            messages.info(request, 'Note: ClamAV antivirus engine is not available. Using basic detection only. See documentation for setup instructions.')
        
        return redirect('malware_analyser:scan_results', scan_id=scan_result.scan_id)
    
    context = {
        'file': file_upload,
        'clamav_available': clamav_available,
        'clamav_version': clamav_version,
    }
    return render(request, 'malware_analyser/scan.html', context)


def perform_clamav_scan(scan_result, file_upload):
    """
    Perform real malware scan using ClamAV antivirus engine.
    
    ⚠️  EDUCATIONAL USE ONLY ⚠️
    This performs REAL malware detection using ClamAV.
    Use only in controlled, isolated environments.
    """
    scanner = get_clamav_scanner()
    
    try:
        # Get the file path
        file_path = file_upload.file.path
        
        # Scan the file
        is_infected, virus_name, scan_details = scanner.scan_file(file_path)
        
        # Update scan result with ClamAV findings
        scan_result.scan_details['clamav_scan'] = scan_details
        scan_result.scan_details['clamav_scan_completed'] = scan_details.get('scan_completed', False)
        
        if is_infected and virus_name:
            scan_result.is_malicious = True
            scan_result.detected_malware = virus_name
            # Set threat level based on detection
            scan_result.threat_level = 'high'
            scan_result.scan_details['clamav_detection'] = virus_name
            logger.warning(f"ClamAV detected malware: {virus_name} in file {file_upload.file_id}")
        elif scan_details.get('scan_completed'):
            # Scan completed successfully, file is clean
            logger.info(f"ClamAV scan clean for file {file_upload.file_id}")
        else:
            # Scan failed or ClamAV unavailable
            error_msg = scan_details.get('error', 'Unknown error')
            logger.error(f"ClamAV scan failed for file {file_upload.file_id}: {error_msg}")
            scan_result.scan_details['clamav_error'] = error_msg
        
        scan_result.save()
        
    except Exception as e:
        logger.error(f"Exception during ClamAV scan: {e}")
        scan_result.scan_details['clamav_exception'] = str(e)
        scan_result.save()


def perform_signature_scan(scan_result, file_upload):
    """
    STUB: Signature-based malware detection.
    
    Real implementation would:
    1. Compare file hashes against known malware databases
    2. Match byte patterns using YARA rules
    3. Check against threat intelligence feeds
    4. Verify digital signatures
    """
    # Get active signatures
    signatures = MalwareSignature.objects.filter(is_active=True)
    
    matched_signatures = []
    
    for signature in signatures:
        if signature.signature_type == 'hash':
            # STUB: Compare hash
            if signature.signature_data == file_upload.file_hash_sha256:
                matched_signatures.append(signature)
                scan_result.is_malicious = True
                scan_result.threat_level = signature.severity
                scan_result.detected_malware = signature.name
        
        elif signature.signature_type == 'pattern':
            # STUB: Pattern matching (simplified)
            # Real implementation would use YARA or similar
            if signature.signature_data.lower() in file_upload.original_filename.lower():
                matched_signatures.append(signature)
    
    # Add matched signatures
    if matched_signatures:
        scan_result.matched_signatures.set(matched_signatures)
        scan_result.scan_details['signature_matches'] = len(matched_signatures)
    
    scan_result.scan_details['signature_scan_completed'] = True
    scan_result.save()


def perform_heuristic_scan(scan_result, file_upload):
    """
    STUB: Heuristic malware detection.
    
    Real implementation would:
    1. Analyze file structure and entropy
    2. Check for suspicious API calls
    3. Detect packing/obfuscation
    4. Analyze behavioral indicators
    5. Use machine learning models
    """
    # STUB: Simple heuristic checks based on filename and size
    suspicious_indicators = []
    
    # Check for suspicious extensions in filename
    suspicious_extensions = ['.exe', '.dll', '.scr', '.bat', '.cmd', '.vbs', '.js']
    for ext in suspicious_extensions:
        if file_upload.original_filename.lower().endswith(ext):
            suspicious_indicators.append(f'Executable file type: {ext}')
    
    # Check for double extensions (e.g., .pdf.exe)
    parts = file_upload.original_filename.lower().split('.')
    if len(parts) > 2:
        suspicious_indicators.append('Multiple file extensions detected')
    
    # STUB: Deterministic detection based on filename patterns for testing
    # Real implementation would never use filename-based detection
    suspicious_keywords = ['malware', 'virus', 'trojan', 'infected', 'payload']
    for keyword in suspicious_keywords:
        if keyword in file_upload.original_filename.lower():
            suspicious_indicators.append(f'Suspicious keyword in filename: {keyword}')
            scan_result.is_malicious = True
            scan_result.threat_level = 'medium'
            scan_result.detected_malware = 'Heuristic.Suspicious'
            break
    
    scan_result.scan_details['heuristic_scan_completed'] = True
    scan_result.scan_details['suspicious_indicators'] = suspicious_indicators
    scan_result.save()


@login_required
def scan_results(request, scan_id):
    """Display scan results."""
    scan_result = get_object_or_404(ScanResult, scan_id=scan_id)
    
    # Check permissions
    if scan_result.performed_by != request.user and not request.user.is_staff:
        log_action(request, 'view_scan_results', 'scan', scan_id, success=False, error_message='Unauthorized access')
        raise PermissionDenied("You don't have permission to view these scan results.")
    
    context = {
        'scan': scan_result,
        'matched_signatures': scan_result.matched_signatures.all(),
    }
    
    log_action(request, 'view_scan_results', 'scan', scan_id)
    return render(request, 'malware_analyser/scan_results.html', context)


@login_required
@require_http_methods(["POST"])
def clean_file(request, file_id):
    """
    Clean/remove detected malware from file.
    
    STUB IMPLEMENTATION: Real cleaning would involve:
    - Quarantine procedures
    - Safe file deletion
    - Disinfection where possible
    - System restoration
    - Registry cleanup (Windows)
    """
    file_upload = get_object_or_404(FileUpload, file_id=file_id)
    
    # Check permissions
    if file_upload.uploaded_by != request.user and not request.user.is_staff:
        log_action(request, 'clean_file', 'file', file_id, success=False, error_message='Unauthorized access')
        raise PermissionDenied("You don't have permission to clean this file.")
    
    # Get the latest scan result
    scan_result = file_upload.scan_results.order_by('-started_at').first()
    if not scan_result:
        messages.error(request, 'No scan results found for this file.')
        return redirect('malware_analyser:dashboard')
    
    action_type = request.POST.get('action', 'quarantine')
    
    # STUB: Perform cleaning action
    success = False
    action_details = ''
    
    if action_type == 'quarantine':
        # STUB: Quarantine file
        action_details = f'File quarantined at /quarantine/{file_upload.file_id} (STUB - not actually moved)'
        success = True
        file_upload.scan_status = 'clean'  # Mark as handled
        
    elif action_type == 'delete':
        # STUB: Delete file
        action_details = f'File marked for deletion (STUB - not actually deleted)'
        success = True
        file_upload.scan_status = 'clean'  # Mark as handled
        
    elif action_type == 'clean':
        # STUB: Attempt to clean/disinfect
        action_details = f'File cleaning attempted (STUB - no actual cleaning performed)'
        success = True
        
    file_upload.save()
    
    # Log the cleaning action
    cleaning_log = CleaningLog.objects.create(
        scan_result=scan_result,
        file=file_upload,
        cleaning_action=action_type,
        performed_by=request.user,
        success=success,
        action_details=action_details,
        backup_location=f'/quarantine/{file_upload.file_id}' if action_type == 'quarantine' else ''
    )
    
    log_action(
        request,
        'clean_file',
        'cleaning',
        cleaning_log.cleaning_id,
        success=success,
        details={'action': action_type, 'file_id': str(file_id)}
    )
    
    if success:
        messages.success(request, f'Cleaning action "{action_type}" completed successfully.')
    else:
        messages.error(request, f'Cleaning action "{action_type}" failed.')
    
    return redirect('malware_analyser:scan_results', scan_id=scan_result.scan_id)


def is_staff_or_superuser(user):
    """Check if user is staff or superuser."""
    return user.is_staff or user.is_superuser


@login_required
@user_passes_test(is_staff_or_superuser)
@require_http_methods(["GET", "POST"])
def create_test_malware(request):
    """
    Create test malware artifacts for safe testing.
    
    ⚠️  CRITICAL WARNING ⚠️
    This function is RESTRICTED to staff/superusers only.
    
    LEGAL REQUIREMENTS:
    - Only use in authorized testing environments
    - Obtain proper authorization before use
    - Document all usage for audit purposes
    
    STUB IMPLEMENTATION: Only creates benign test files.
    NO ACTUAL MALWARE IS CREATED.
    """
    if request.method == 'POST':
        form = TestMalwareCreationForm(request.POST)
        if form.is_valid():
            try:
                with transaction.atomic():
                    artifact = form.save(commit=False)
                    artifact.created_by = request.user
                    artifact.save()
                    
                    # Generate test content based on type
                    if artifact.artifact_type == 'eicar_test':
                        artifact.generate_eicar_test()
                    else:
                        artifact.generate_benign_test()
                    
                    log_action(
                        request,
                        'create_test_artifact',
                        'test_malware',
                        artifact.artifact_id,
                        details={
                            'name': artifact.name,
                            'type': artifact.artifact_type,
                            'purpose': artifact.purpose
                        }
                    )
                    
                    messages.success(request, f'Test artifact "{artifact.name}" created successfully.')
                    return redirect('malware_analyser:test_artifact_details', artifact_id=artifact.artifact_id)
                    
            except Exception as e:
                error_msg = f'Error creating test artifact: {str(e)}'
                log_action(request, 'create_test_artifact', 'test_malware', success=False, error_message=error_msg)
                messages.error(request, error_msg)
        else:
            messages.error(request, 'Invalid form data. Please check your input.')
    else:
        form = TestMalwareCreationForm()
    
    context = {
        'form': form,
    }
    return render(request, 'malware_analyser/create_test_malware.html', context)


@login_required
@user_passes_test(is_staff_or_superuser)
def test_artifact_details(request, artifact_id):
    """View details of a test malware artifact."""
    artifact = get_object_or_404(TestMalwareArtifact, artifact_id=artifact_id)
    
    log_action(request, 'view_test_artifact', 'test_malware', artifact_id)
    
    context = {
        'artifact': artifact,
    }
    return render(request, 'malware_analyser/test_artifact_details.html', context)


@login_required
@user_passes_test(is_staff_or_superuser)
def manage_signatures(request):
    """Manage malware signatures."""
    if request.method == 'POST':
        form = MalwareSignatureForm(request.POST)
        if form.is_valid():
            signature = form.save(commit=False)
            signature.created_by = request.user
            signature.save()
            
            log_action(
                request,
                'create_signature',
                'signature',
                signature.id,
                details={'name': signature.name, 'type': signature.signature_type}
            )
            
            messages.success(request, f'Signature "{signature.name}" created successfully.')
            return redirect('malware_analyser:manage_signatures')
        else:
            messages.error(request, 'Invalid form data.')
    else:
        form = MalwareSignatureForm()
    
    signatures = MalwareSignature.objects.all().order_by('-created_at')
    
    context = {
        'form': form,
        'signatures': signatures,
    }
    return render(request, 'malware_analyser/manage_signatures.html', context)


@login_required
def analysis_goals(request):
    """View and manage analysis goals."""
    from .models import AnalysisGoal
    
    goals = AnalysisGoal.objects.all()
    default_goals = AnalysisGoal.objects.filter(is_default=True)
    
    context = {
        'goals': goals,
        'default_goals': default_goals,
    }
    
    log_action(request, 'view_analysis_goals', 'analysis_goals')
    return render(request, 'malware_analyser/analysis_goals.html', context)


@login_required
def analysis_techniques(request):
    """View analysis techniques and guidance."""
    from .models import AnalysisTechnique
    
    basic_static = AnalysisTechnique.objects.filter(category='basic_static', is_active=True)
    basic_dynamic = AnalysisTechnique.objects.filter(category='basic_dynamic', is_active=True)
    advanced_static = AnalysisTechnique.objects.filter(category='advanced_static', is_active=True)
    advanced_dynamic = AnalysisTechnique.objects.filter(category='advanced_dynamic', is_active=True)
    
    context = {
        'basic_static': basic_static,
        'basic_dynamic': basic_dynamic,
        'advanced_static': advanced_static,
        'advanced_dynamic': advanced_dynamic,
    }
    
    log_action(request, 'view_analysis_techniques', 'analysis_techniques')
    return render(request, 'malware_analyser/analysis_techniques.html', context)


@login_required
def best_practices(request):
    """View safety best practices and checklists."""
    from .models import BestPractice
    
    practices_by_category = {}
    for category, _ in BestPractice.PRACTICE_CATEGORIES:
        practices = BestPractice.objects.filter(category=category, is_active=True)
        if practices.exists():
            practices_by_category[category] = practices
    
    mandatory_practices = BestPractice.objects.filter(is_mandatory=True, is_active=True)
    
    context = {
        'practices_by_category': practices_by_category,
        'mandatory_practices': mandatory_practices,
    }
    
    log_action(request, 'view_best_practices', 'best_practices')
    return render(request, 'malware_analyser/best_practices.html', context)


@login_required
def static_analysis(request, scan_id):
    """Perform and view static analysis with TEXTBOOK-LEVEL ADVANCED ENGINE."""
    from .models import StaticAnalysisResult, AnalysisTechnique
    from .advanced_engine import perform_advanced_analysis
    from .pe_analysis_textbook import perform_textbook_analysis
    import hashlib
    import json
    
    scan_result = get_object_or_404(ScanResult, scan_id=scan_id)
    
    # Check permissions
    if scan_result.performed_by != request.user and not request.user.is_staff:
        raise PermissionDenied("You don't have permission to analyze this scan.")
    
    # Get or create static analysis result
    static_analysis, created = StaticAnalysisResult.objects.get_or_create(
        scan_result=scan_result
    )
    
    if request.method == 'POST' and (created or request.POST.get('reanalyze')):
        # Perform TEXTBOOK-LEVEL ADVANCED static analysis
        file_upload = scan_result.file
        
        # Calculate real hashes
        try:
            file_path = file_upload.file.path
            with open(file_path, 'rb') as f:
                file_content = f.read()
                static_analysis.md5_hash = hashlib.md5(file_content).hexdigest()
                static_analysis.sha1_hash = hashlib.sha1(file_content).hexdigest()
                static_analysis.sha256_hash = hashlib.sha256(file_content).hexdigest()
                
                # Calculate entropy (basic implementation)
                import math
                from collections import Counter
                if len(file_content) > 0:
                    counter = Counter(file_content)
                    entropy = 0
                    for count in counter.values():
                        p = count / len(file_content)
                        if p > 0:
                            entropy -= p * math.log2(p)
                    static_analysis.entropy = entropy
                    
                    # Check if packed (high entropy suggests packing)
                    if entropy > 7.0:
                        static_analysis.is_packed = True
                        static_analysis.packer_detected = "Possible packing detected (high entropy)"
                        static_analysis.unpacking_suggestions = "Consider using tools like UPX, PEiD, or manual unpacking"
            
            # ⭐ TEXTBOOK-LEVEL ADVANCED ANALYSIS ENGINE ⭐
            logger.info(f"Running TEXTBOOK-LEVEL ADVANCED analysis engine on {file_path}")
            advanced_results = perform_advanced_analysis(file_path)
            
            # ⭐ NEW: TEXTBOOK-LEVEL PE ANALYSIS ⭐
            textbook_analysis = perform_textbook_analysis(file_path)
            
            # Merge textbook analysis with PE data
            if advanced_results.get('pe_analysis'):
                pe_data = advanced_results['pe_analysis']
                
                # Add textbook-level details
                pe_data['textbook_analysis'] = textbook_analysis
                pe_data['dos_header'] = textbook_analysis.get('dos_header', {})
                pe_data['coff_header'] = textbook_analysis.get('coff_header', {})
                pe_data['optional_header'] = textbook_analysis.get('optional_header', {})
                pe_data['packer_detection'] = textbook_analysis.get('packer_detection', {})
                pe_data['section_analysis'] = textbook_analysis.get('section_analysis', [])
                
                static_analysis.pe_data = pe_data
                
                # Extract imports for display
                if pe_data.get('imports'):
                    static_analysis.imports = [
                        f"{imp['dll']}: {', '.join(imp['functions'][:5])}" 
                        for imp in pe_data['imports'][:10]
                    ]
                
                # Extract exports
                if pe_data.get('exports'):
                    static_analysis.exports = [
                        f"{exp['name']} (ord: {exp['ordinal']})" 
                        for exp in pe_data['exports'][:20]
                    ]
                
                # Store dependencies
                if pe_data.get('imports'):
                    static_analysis.dependencies = [imp['dll'] for imp in pe_data['imports'][:20]]
                
                # ⭐ PACKER DETECTION ⭐
                packer_info = pe_data.get('packer_detection', {})
                if packer_info.get('detected'):
                    static_analysis.packer_detected = f"{packer_info.get('packer_name', 'Unknown')} ({packer_info.get('confidence', 'Unknown')} confidence)"
                    static_analysis.is_packed = True
                    
                    # Add packer details to unpacking suggestions
                    if packer_info.get('description'):
                        static_analysis.unpacking_suggestions = f"{packer_info['description']}\nIndicators: {', '.join(packer_info.get('indicators', []))}"
            
            # Store YARA scan results
            if advanced_results.get('yara_scan'):
                yara_results = advanced_results['yara_scan']
                if yara_results.get('matches'):
                    static_analysis.yara_matches = [
                        {
                            'rule': match['rule'],
                            'tags': match['tags'],
                            'meta': match['meta']
                        }
                        for match in yara_results['matches']
                    ]
                    # Flag as potentially malicious if YARA matches found
                    if len(yara_results['matches']) > 0:
                        scan_result.is_malicious = True
                        scan_result.threat_level = 'high'
                        scan_result.detected_malware = f"YARA: {yara_results['matches'][0]['rule']}"
                        scan_result.save()
            
            # Store ML prediction
            if advanced_results.get('ml_prediction'):
                ml_pred = advanced_results['ml_prediction']
                static_analysis.scan_result.scan_details['ml_prediction'] = ml_pred
                
                # Update threat assessment
                if ml_pred.get('is_malicious') and ml_pred.get('confidence', 0) > 0.7:
                    if not scan_result.is_malicious:
                        scan_result.is_malicious = True
                        scan_result.threat_level = 'medium'
                        scan_result.detected_malware = f"ML: Malware (confidence: {ml_pred['confidence']:.2%})"
                        scan_result.save()
            
        except Exception as e:
            logger.error(f"Error during advanced static analysis: {e}")
            messages.warning(request, f'Some advanced features encountered errors: {str(e)}')
        
        # Extract strings (simplified - first 1000 printable chars)
        try:
            printable_chars = ''.join(chr(b) if 32 <= b < 127 else ' ' for b in file_content[:10000])
            static_analysis.strings_extracted = printable_chars[:5000]  # Limit size
            
            # Check for suspicious strings
            suspicious_keywords = ['http://', 'https://', '.exe', '.dll', 'cmd', 'powershell', 'download', 'payload', 'CreateRemoteThread', 'VirtualAlloc']
            suspicious = []
            for keyword in suspicious_keywords:
                if keyword.lower() in printable_chars.lower():
                    suspicious.append(keyword)
            static_analysis.suspicious_strings = suspicious
        except:
            pass
        
        static_analysis.save()
        
        # Add techniques used (including advanced)
        basic_static_techniques = AnalysisTechnique.objects.filter(category='basic_static', is_active=True)
        advanced_static_techniques = AnalysisTechnique.objects.filter(category='advanced_static', is_active=True)
        static_analysis.techniques_used.set(list(basic_static_techniques) + list(advanced_static_techniques))
        
        messages.success(request, '✨ Advanced static analysis completed successfully with PE parsing, YARA scanning, and ML detection!')
        log_action(request, 'perform_advanced_static_analysis', 'static_analysis', scan_id)
    
    context = {
        'scan': scan_result,
        'static_analysis': static_analysis,
    }
    return render(request, 'malware_analyser/static_analysis.html', context)


@login_required
def dynamic_analysis(request, scan_id):
    """Perform and view dynamic analysis."""
    from .models import DynamicAnalysisResult, AnalysisTechnique
    
    scan_result = get_object_or_404(ScanResult, scan_id=scan_id)
    
    # Check permissions
    if scan_result.performed_by != request.user and not request.user.is_staff:
        raise PermissionDenied("You don't have permission to analyze this scan.")
    
    # Get or create dynamic analysis result
    dynamic_analysis, created = DynamicAnalysisResult.objects.get_or_create(
        scan_result=scan_result
    )
    
    if request.method == 'POST' and created:
        # Perform dynamic analysis (STUB - simulated)
        dynamic_analysis.sandbox_status = 'completed'
        dynamic_analysis.execution_time = 5.0
        
        # Stub data for demonstration
        dynamic_analysis.processes_created = [
            {'name': 'sample.exe', 'pid': 1234, 'parent_pid': 0}
        ]
        dynamic_analysis.files_created = ['/tmp/malware_temp.dat']
        dynamic_analysis.network_connections = [
            {'protocol': 'TCP', 'destination': '192.0.2.1:80', 'status': 'ESTABLISHED'}
        ]
        dynamic_analysis.dns_queries = ['malicious-domain.example']
        
        # Check for evasion techniques (STUB)
        dynamic_analysis.anti_vm_detected = False
        dynamic_analysis.anti_debug_detected = False
        dynamic_analysis.injection_detected = False
        
        dynamic_analysis.save()
        
        # Add techniques used
        basic_dynamic_techniques = AnalysisTechnique.objects.filter(category='basic_dynamic', is_active=True)
        dynamic_analysis.techniques_used.set(basic_dynamic_techniques)
        
        messages.success(request, 'Dynamic analysis completed successfully. (Note: This is a stub implementation)')
        log_action(request, 'perform_dynamic_analysis', 'dynamic_analysis', scan_id)
    
    context = {
        'scan': scan_result,
        'dynamic_analysis': dynamic_analysis,
    }
    return render(request, 'malware_analyser/dynamic_analysis.html', context)


@login_required
def generate_report(request, scan_id):
    """Generate comprehensive analysis report."""
    from .models import AnalysisReport, AnalysisGoal, MalwareType
    import json
    from datetime import datetime
    
    scan_result = get_object_or_404(ScanResult, scan_id=scan_id)
    
    # Check permissions
    if scan_result.performed_by != request.user and not request.user.is_staff:
        raise PermissionDenied("You don't have permission to generate this report.")
    
    if request.method == 'POST':
        report_format = request.POST.get('format', 'json')
        
        # Create report
        report = AnalysisReport.objects.create(
            scan_result=scan_result,
            report_format=report_format,
            created_by=request.user
        )
        
        # Generate executive summary
        report.executive_summary = f"""
        Analysis Report for: {scan_result.file.original_filename}
        Scan Date: {scan_result.started_at.strftime('%Y-%m-%d %H:%M:%S')}
        Threat Level: {scan_result.get_threat_level_display()}
        Malicious: {'Yes' if scan_result.is_malicious else 'No'}
        """
        
        # Add detailed findings
        findings = []
        
        # Static analysis findings
        if hasattr(scan_result, 'static_analysis'):
            static = scan_result.static_analysis
            findings.append(f"MD5: {static.md5_hash}")
            findings.append(f"SHA256: {static.sha256_hash}")
            if static.is_packed:
                findings.append(f"Packing Detected: {static.packer_detected}")
            if static.entropy:
                findings.append(f"Entropy: {static.entropy:.2f}")
        
        # Dynamic analysis findings
        if hasattr(scan_result, 'dynamic_analysis'):
            dynamic = scan_result.dynamic_analysis
            if dynamic.network_connections:
                findings.append(f"Network Connections: {len(dynamic.network_connections)}")
            if dynamic.files_created:
                findings.append(f"Files Created: {len(dynamic.files_created)}")
        
        report.detailed_findings = "\n".join(findings)
        
        # Add IOCs
        iocs = {
            'hashes': {},
            'network': [],
            'files': []
        }
        
        if hasattr(scan_result, 'static_analysis'):
            static = scan_result.static_analysis
            iocs['hashes'] = {
                'md5': static.md5_hash,
                'sha1': static.sha1_hash,
                'sha256': static.sha256_hash
            }
        
        if hasattr(scan_result, 'dynamic_analysis'):
            dynamic = scan_result.dynamic_analysis
            iocs['network'] = dynamic.network_connections
            iocs['files'] = dynamic.files_created
        
        report.indicators_of_compromise = iocs
        
        # Add recommendations
        if scan_result.is_malicious:
            report.recommendations = """
            1. Quarantine the infected file immediately
            2. Scan all systems that may have been exposed
            3. Change passwords for any accounts accessed from infected systems
            4. Monitor network traffic for IOCs identified in this report
            5. Update antivirus signatures and security policies
            """
        else:
            report.recommendations = "No immediate action required. File appears clean."
        
        report.save()
        
        # Export report based on format
        if report_format == 'json':
            report_data = {
                'file': scan_result.file.original_filename,
                'scan_date': scan_result.started_at.isoformat(),
                'is_malicious': scan_result.is_malicious,
                'threat_level': scan_result.threat_level,
                'summary': report.executive_summary,
                'findings': report.detailed_findings,
                'iocs': report.indicators_of_compromise,
                'recommendations': report.recommendations
            }
            
            from django.http import JsonResponse
            response = JsonResponse(report_data, json_dumps_params={'indent': 2})
            response['Content-Disposition'] = f'attachment; filename="report_{scan_id}.json"'
            return response
        
        messages.success(request, f'Report generated successfully in {report_format.upper()} format.')
        log_action(request, 'generate_report', 'analysis_report', report.report_id)
        return redirect('malware_analyser:scan_results', scan_id=scan_id)
    
    context = {
        'scan': scan_result,
    }
    return render(request, 'malware_analyser/generate_report.html', context)
