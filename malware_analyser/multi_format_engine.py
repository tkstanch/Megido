"""
Multi-Format Analysis Engine for Malware Analyzer

Provides unified analysis for a wide range of file formats:
- ELF (Linux/Android executables)
- Mach-O (macOS/iOS executables)
- APK / DEX (Android packages)
- Documents: OLE/VBA (Office), PDF
- Firmware images
- Archive files (ZIP, TAR, etc.)

All optional dependencies are handled gracefully via ImportError.
"""

import logging
import os
import struct
import hashlib
import zipfile
import tarfile
import math
from typing import Dict, List, Optional, Any
from collections import Counter

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Optional dependency guards
# ---------------------------------------------------------------------------

try:
    from elftools.elf.elffile import ELFFile
    from elftools.elf.dynamic import DynamicSection
    from elftools.elf.sections import SymbolTableSection
    ELFTOOLS_AVAILABLE = True
except ImportError:
    ELFTOOLS_AVAILABLE = False
    logger.info("pyelftools not available; ELF analysis will use basic heuristics")

try:
    from macholib.MachO import MachO
    from macholib.mach_o import (
        LC_LOAD_DYLIB, LC_SYMTAB, LC_DYSYMTAB, LC_SEGMENT_64, LC_SEGMENT,
        MH_EXECUTE, MH_DYLIB, MH_BUNDLE,
    )
    MACHOLIB_AVAILABLE = True
except ImportError:
    MACHOLIB_AVAILABLE = False
    logger.info("macholib not available; Mach-O analysis will use basic heuristics")

try:
    from androguard.core.bytecodes.apk import APK
    from androguard.core.bytecodes.dvm import DalvikVMFormat
    ANDROGUARD_AVAILABLE = True
except ImportError:
    ANDROGUARD_AVAILABLE = False
    logger.info("androguard not available; APK/DEX analysis will use basic heuristics")

try:
    import olefile
    OLEFILE_AVAILABLE = True
except ImportError:
    OLEFILE_AVAILABLE = False
    logger.info("olefile not available; OLE analysis will use basic heuristics")

try:
    from oletools.olevba import VBA_Parser
    from oletools.msodde import process_file as msodde_process
    OLETOOLS_AVAILABLE = True
except ImportError:
    OLETOOLS_AVAILABLE = False
    logger.info("oletools not available; VBA/macro analysis disabled")

try:
    import pdfminer
    from pdfminer.high_level import extract_text as pdf_extract_text
    from pdfminer.pdfpage import PDFPage
    from pdfminer.pdfdocument import PDFDocument
    from pdfminer.pdfparser import PDFParser
    PDFMINER_AVAILABLE = True
except ImportError:
    PDFMINER_AVAILABLE = False
    logger.info("pdfminer not available; PDF analysis will use basic heuristics")

try:
    import binwalk
    BINWALK_AVAILABLE = True
except ImportError:
    BINWALK_AVAILABLE = False
    logger.info("binwalk not available; firmware/archive analysis will use basic heuristics")


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _entropy(data: bytes) -> float:
    """Calculate Shannon entropy of a byte sequence."""
    if not data:
        return 0.0
    counts = Counter(data)
    length = len(data)
    return -sum((c / length) * math.log2(c / length) for c in counts.values() if c)


def _file_hashes(path: str) -> Dict[str, str]:
    """Return MD5, SHA1, SHA256 for a file."""
    md5 = hashlib.md5()
    sha1 = hashlib.sha1()
    sha256 = hashlib.sha256()
    with open(path, "rb") as fh:
        for chunk in iter(lambda: fh.read(65536), b""):
            md5.update(chunk)
            sha1.update(chunk)
            sha256.update(chunk)
    return {"md5": md5.hexdigest(), "sha1": sha1.hexdigest(), "sha256": sha256.hexdigest()}


def _detect_format(path: str) -> str:
    """Detect file format from magic bytes."""
    with open(path, "rb") as fh:
        magic = fh.read(8)

    if magic[:4] == b"\x7fELF":
        return "elf"
    if magic[:4] in (b"\xfe\xed\xfa\xce", b"\xce\xfa\xed\xfe",
                     b"\xfe\xed\xfa\xcf", b"\xcf\xfa\xed\xfe",
                     b"\xca\xfe\xba\xbe"):
        return "macho"
    if magic[:2] == b"PK":
        # Could be APK, DOCX, XLSX, ZIP
        return "zip_based"
    if magic[:4] == b"\xd0\xcf\x11\xe0":
        return "ole"
    if magic[:4] == b"%PDF":
        return "pdf"
    if magic[:5] == b"Rar!\x1a":
        return "rar"
    if magic[:3] == b"\x1f\x8b\x08" or magic[:2] == b"\x1f\x9d":
        return "gz"
    if magic[:3] == b"BZh":
        return "bz2"
    if magic[:6] == b"\xfd7zXZ\x00":
        return "xz"
    if magic[:4] == b"DEXN":
        return "dex"
    return "unknown"


# ---------------------------------------------------------------------------
# ELF Analyzer
# ---------------------------------------------------------------------------

class ELFAnalyzer:
    """Analyzes ELF binaries (Linux, Android native libs)."""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "elf",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "imports": [],
            "exports": [],
            "sections": [],
            "anomalies": [],
            "suspicious_strings": [],
        }

        if ELFTOOLS_AVAILABLE:
            result.update(self._analyze_with_elftools())
        else:
            result.update(self._basic_analysis())

        return result

    def _analyze_with_elftools(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            with open(self.file_path, "rb") as fh:
                elf = ELFFile(fh)
                data["arch"] = elf.get_machine_arch()
                data["entry_point"] = hex(elf.header.e_entry)
                data["type"] = elf.header.e_type

                sections = []
                for section in elf.iter_sections():
                    entropy = _entropy(section.data()) if section.data_size > 0 else 0.0
                    sections.append({
                        "name": section.name,
                        "size": section.data_size,
                        "offset": section.header.sh_offset,
                        "entropy": round(entropy, 3),
                        "flags": section.header.sh_flags,
                    })
                    if entropy > 7.2:
                        data.setdefault("anomalies", []).append(
                            f"High entropy section '{section.name}': {entropy:.2f}"
                        )
                data["sections"] = sections

                imports: List[str] = []
                exports: List[str] = []
                for section in elf.iter_sections():
                    if isinstance(section, SymbolTableSection):
                        for sym in section.iter_symbols():
                            if sym.entry.st_shndx == "SHN_UNDEF" and sym.name:
                                imports.append(sym.name)
                            elif sym.name:
                                exports.append(sym.name)
                data["imports"] = imports
                data["exports"] = exports

                suspicious = [
                    "ptrace", "fork", "execve", "/bin/sh", "chmod", "system",
                    "popen", "dlopen", "mprotect", "mmap", "strcpy", "gets",
                ]
                data["suspicious_strings"] = [s for s in imports if any(kw in s for kw in suspicious)]

        except Exception as exc:
            logger.error("ELF analysis error: %s", exc)
            data["error"] = str(exc)

        return data

    def _basic_analysis(self) -> Dict[str, Any]:
        """Heuristic ELF analysis without pyelftools."""
        data: Dict[str, Any] = {}
        try:
            with open(self.file_path, "rb") as fh:
                raw = fh.read()
            # ELF e_machine at offset 0x12
            if len(raw) >= 20:
                e_machine = struct.unpack_from("<H", raw, 18)[0]
                arch_map = {3: "x86", 62: "x86_64", 40: "ARM", 183: "AArch64", 8: "MIPS"}
                data["arch"] = arch_map.get(e_machine, f"unknown({e_machine})")
            data["entropy"] = round(_entropy(raw), 3)
            suspicious_strs = [b"ptrace", b"/bin/sh", b"system", b"chmod"]
            data["suspicious_strings"] = [s.decode() for s in suspicious_strs if s in raw]
        except Exception as exc:
            logger.error("Basic ELF analysis error: %s", exc)
            data["error"] = str(exc)
        return data


# ---------------------------------------------------------------------------
# Mach-O Analyzer
# ---------------------------------------------------------------------------

class MachOAnalyzer:
    """Analyzes Mach-O binaries (macOS, iOS)."""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "macho",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "dylibs": [],
            "segments": [],
            "anomalies": [],
        }

        if MACHOLIB_AVAILABLE:
            result.update(self._analyze_with_macholib())
        else:
            result.update(self._basic_analysis())

        return result

    def _analyze_with_macholib(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            macho = MachO(self.file_path)
            headers = []
            dylibs: List[str] = []

            for header in macho.headers:
                arch = header.MH_MAGIC
                headers.append(hex(arch))
                for load_cmd, cmd, data_bytes in header.commands:
                    if load_cmd.cmd == LC_LOAD_DYLIB:
                        # dylib name is encoded in data_bytes
                        name_offset = cmd.name - 8
                        if name_offset < len(data_bytes):
                            name = data_bytes[name_offset:].split(b"\x00")[0].decode("utf-8", errors="replace")
                            dylibs.append(name)

            data["headers"] = headers
            data["dylibs"] = dylibs

            suspicious_libs = ["libdl", "libc.dylib"]
            data["suspicious_imports"] = [d for d in dylibs if any(s in d for s in suspicious_libs)]

        except Exception as exc:
            logger.error("Mach-O analysis error: %s", exc)
            data["error"] = str(exc)

        return data

    def _basic_analysis(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            with open(self.file_path, "rb") as fh:
                raw = fh.read(4096)
            data["entropy"] = round(_entropy(raw), 3)
        except Exception as exc:
            data["error"] = str(exc)
        return data


# ---------------------------------------------------------------------------
# APK / DEX Analyzer
# ---------------------------------------------------------------------------

class APKAnalyzer:
    """Analyzes Android APK packages and DEX bytecode."""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "apk",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "permissions": [],
            "activities": [],
            "services": [],
            "receivers": [],
            "providers": [],
            "api_calls": [],
            "anomalies": [],
        }

        if ANDROGUARD_AVAILABLE:
            result.update(self._analyze_with_androguard())
        else:
            result.update(self._basic_analysis())

        return result

    def _analyze_with_androguard(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            apk = APK(self.file_path)
            data["package"] = apk.get_package()
            data["version_name"] = apk.get_androidversion_name()
            data["version_code"] = apk.get_androidversion_code()
            data["min_sdk"] = apk.get_min_sdk_version()
            data["target_sdk"] = apk.get_target_sdk_version()
            data["permissions"] = list(apk.get_permissions())
            data["activities"] = list(apk.get_activities())
            data["services"] = list(apk.get_services())
            data["receivers"] = list(apk.get_receivers())
            data["providers"] = list(apk.get_providers())

            dangerous_permissions = {
                "android.permission.READ_SMS",
                "android.permission.SEND_SMS",
                "android.permission.READ_CONTACTS",
                "android.permission.RECORD_AUDIO",
                "android.permission.CAMERA",
                "android.permission.ACCESS_FINE_LOCATION",
                "android.permission.READ_CALL_LOG",
                "android.permission.PROCESS_OUTGOING_CALLS",
                "android.permission.RECEIVE_BOOT_COMPLETED",
            }
            found_dangerous = [p for p in data["permissions"] if p in dangerous_permissions]
            if found_dangerous:
                data.setdefault("anomalies", []).append(
                    f"Dangerous permissions: {', '.join(found_dangerous)}"
                )

        except Exception as exc:
            logger.error("APK analysis error: %s", exc)
            data["error"] = str(exc)

        return data

    def _basic_analysis(self) -> Dict[str, Any]:
        """ZIP-based APK inspection without androguard."""
        data: Dict[str, Any] = {}
        try:
            with zipfile.ZipFile(self.file_path, "r") as zf:
                names = zf.namelist()
                data["file_count"] = len(names)
                data["dex_files"] = [n for n in names if n.endswith(".dex")]
                data["native_libs"] = [n for n in names if n.endswith(".so")]
                data["assets"] = [n for n in names if n.startswith("assets/")]
        except Exception as exc:
            data["error"] = str(exc)
        return data


class DEXAnalyzer:
    """Analyzes raw DEX bytecode files."""

    # DEX magic bytes
    DEX_MAGIC = b"dex\n"

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "dex",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
        }
        try:
            with open(self.file_path, "rb") as fh:
                header = fh.read(112)
            if header[:4] == self.DEX_MAGIC:
                result["version"] = header[4:7].decode("ascii", errors="replace")
            else:
                result["anomalies"] = ["File does not start with DEX magic bytes"]

            if ANDROGUARD_AVAILABLE:
                dex = DalvikVMFormat(open(self.file_path, "rb").read())
                classes = [c.get_name() for c in dex.get_classes()]
                result["class_count"] = len(classes)
                result["sample_classes"] = classes[:20]
        except Exception as exc:
            logger.error("DEX analysis error: %s", exc)
            result["error"] = str(exc)

        return result


# ---------------------------------------------------------------------------
# Document Analyzers
# ---------------------------------------------------------------------------

class OLEAnalyzer:
    """Analyzes OLE2 compound files (doc, xls, ppt) for malicious macros/embedded objects."""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "ole",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "streams": [],
            "macros": [],
            "indicators": [],
            "anomalies": [],
        }

        if OLEFILE_AVAILABLE:
            result.update(self._list_streams())
        if OLETOOLS_AVAILABLE:
            result.update(self._extract_vba())

        return result

    def _list_streams(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            ole = olefile.OleFileIO(self.file_path)
            streams = ["/".join(e) for e in ole.listdir()]
            data["streams"] = streams
            suspicious_streams = ["Macros", "VBA", "AutoOpen", "AutoExec", "Document"]
            data["suspicious_streams"] = [s for s in streams if any(kw in s for kw in suspicious_streams)]
            ole.close()
        except Exception as exc:
            logger.error("OLE stream listing error: %s", exc)
            data["error"] = str(exc)
        return data

    def _extract_vba(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            vba = VBA_Parser(self.file_path)
            if vba.detect_vba_macros():
                macros = []
                indicators = []
                for _, _, vba_filename, vba_code in vba.extract_macros():
                    macros.append({"filename": vba_filename, "code_length": len(vba_code)})
                    suspicious_keywords = [
                        "Shell", "CreateObject", "WScript", "PowerShell",
                        "AutoOpen", "Document_Open", "Workbook_Open",
                        "Chr(", "Base64", "URLDownloadToFile", "XMLHTTP",
                        "WinHttp", "Environ", "CreateProcess",
                    ]
                    found = [kw for kw in suspicious_keywords if kw.lower() in vba_code.lower()]
                    if found:
                        indicators.append({"file": vba_filename, "keywords": found})
                data["macros"] = macros
                data["indicators"] = indicators
            vba.close()
        except Exception as exc:
            logger.error("VBA extraction error: %s", exc)
            data["vba_error"] = str(exc)
        return data


class PDFAnalyzer:
    """Analyzes PDF files for embedded JavaScript, suspicious objects, and exploits."""

    SUSPICIOUS_KEYWORDS = [
        b"/JavaScript", b"/JS", b"/OpenAction", b"/AA",
        b"/Launch", b"/EmbeddedFile", b"/RichMedia",
        b"eval(", b"unescape(", b"shellcode",
    ]

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "pdf",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "page_count": 0,
            "javascript_present": False,
            "embedded_files": False,
            "suspicious_keywords": [],
            "anomalies": [],
        }

        try:
            with open(self.file_path, "rb") as fh:
                raw = fh.read()

            found_keywords = [kw.decode("latin-1") for kw in self.SUSPICIOUS_KEYWORDS if kw in raw]
            result["suspicious_keywords"] = found_keywords
            result["javascript_present"] = any(kw in (b"/JavaScript", b"/JS") for kw in self.SUSPICIOUS_KEYWORDS if kw in raw)
            result["embedded_files"] = b"/EmbeddedFile" in raw

            if PDFMINER_AVAILABLE:
                result.update(self._analyze_with_pdfminer())

        except Exception as exc:
            logger.error("PDF analysis error: %s", exc)
            result["error"] = str(exc)

        return result

    def _analyze_with_pdfminer(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        try:
            with open(self.file_path, "rb") as fh:
                parser = PDFParser(fh)
                doc = PDFDocument(parser)
                pages = list(PDFPage.create_pages(doc))
                data["page_count"] = len(pages)
        except Exception as exc:
            logger.warning("pdfminer analysis error: %s", exc)
        return data


# ---------------------------------------------------------------------------
# Firmware Analyzer
# ---------------------------------------------------------------------------

class FirmwareAnalyzer:
    """Analyzes firmware images using binwalk for embedded component detection."""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "firmware",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "components": [],
            "strings_of_interest": [],
            "entropy_profile": {},
        }

        with open(self.file_path, "rb") as fh:
            raw = fh.read()

        result["entropy"] = round(_entropy(raw), 3)
        result["strings_of_interest"] = self._extract_strings(raw)

        if BINWALK_AVAILABLE:
            result["components"] = self._binwalk_scan()
        else:
            result["components"] = self._heuristic_components(raw)

        return result

    def _binwalk_scan(self) -> List[Dict]:
        components = []
        try:
            for module in binwalk.scan(self.file_path, signature=True, quiet=True):
                for result in module.results:
                    components.append({
                        "offset": result.offset,
                        "description": result.description,
                    })
        except Exception as exc:
            logger.error("binwalk scan error: %s", exc)
        return components

    def _heuristic_components(self, raw: bytes) -> List[Dict]:
        """Detect common firmware components by magic bytes."""
        components = []
        magic_map = {
            b"\x7fELF": "ELF binary",
            b"PK\x03\x04": "ZIP archive",
            b"\x1f\x8b": "GZIP compressed data",
            b"BZh": "BZIP2 compressed data",
            b"\xfd7zXZ\x00": "XZ compressed data",
            b"hsqs": "Squashfs filesystem",
            b"qshs": "Squashfs filesystem (BE)",
            b"\x45\x3d\xd8\x1b": "JFFS2 filesystem",
            b"\x19\x85\x20\x03": "UBIFS superblock",
        }
        for magic, description in magic_map.items():
            offset = 0
            while True:
                idx = raw.find(magic, offset)
                if idx == -1:
                    break
                components.append({"offset": idx, "description": description})
                offset = idx + 1
        return components

    @staticmethod
    def _extract_strings(raw: bytes, min_length: int = 8) -> List[str]:
        """Extract printable ASCII strings from binary data."""
        pattern = re.compile(rb"[ -~]{" + str(min_length).encode() + rb",}")
        strings = [m.group(0).decode("ascii", errors="replace") for m in pattern.finditer(raw)]

        interesting_patterns = [
            "passwd", "password", "admin", "root", "shell", "telnet",
            "/bin/sh", "busybox", "wget", "curl", "192.168.", "10.0.",
        ]
        return [s for s in strings if any(p in s.lower() for p in interesting_patterns)][:100]


# ---------------------------------------------------------------------------
# Archive Analyzer
# ---------------------------------------------------------------------------

class ArchiveAnalyzer:
    """Analyzes archive files (ZIP, TAR, etc.) for nested malicious content."""

    def __init__(self, file_path: str):
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        result: Dict[str, Any] = {
            "format": "archive",
            "hashes": _file_hashes(self.file_path),
            "size": os.path.getsize(self.file_path),
            "files": [],
            "nested_executables": [],
            "suspicious_extensions": [],
            "anomalies": [],
        }

        ext = os.path.splitext(self.file_path)[1].lower()
        if ext in (".zip", ".jar", ".apk", ".docx", ".xlsx", ".pptx"):
            result.update(self._analyze_zip())
        elif ext in (".tar", ".tgz", ".tar.gz", ".tar.bz2", ".tar.xz"):
            result.update(self._analyze_tar())
        else:
            # Try ZIP first, then TAR
            try:
                result.update(self._analyze_zip())
            except Exception:
                try:
                    result.update(self._analyze_tar())
                except Exception as exc:
                    result["error"] = f"Unsupported archive format: {exc}"

        return result

    def _analyze_zip(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {"archive_type": "zip"}
        suspicious_ext = {".exe", ".dll", ".bat", ".cmd", ".ps1", ".vbs", ".js",
                          ".scr", ".pif", ".com", ".jar", ".hta", ".wsf"}
        try:
            with zipfile.ZipFile(self.file_path, "r") as zf:
                files = []
                nested_executables = []
                suspicious_extensions = []
                for info in zf.infolist():
                    ext = os.path.splitext(info.filename)[1].lower()
                    entry = {
                        "name": info.filename,
                        "size": info.file_size,
                        "compress_size": info.compress_size,
                        "crc": hex(info.CRC),
                    }
                    files.append(entry)
                    if ext in suspicious_ext:
                        nested_executables.append(info.filename)
                    if ext in (".js", ".vbs", ".ps1", ".bat"):
                        suspicious_extensions.append(info.filename)
                data["files"] = files
                data["nested_executables"] = nested_executables
                data["suspicious_extensions"] = suspicious_extensions
                data["file_count"] = len(files)
        except Exception as exc:
            data["error"] = str(exc)
        return data

    def _analyze_tar(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {"archive_type": "tar"}
        try:
            with tarfile.open(self.file_path, "r:*") as tf:
                members = tf.getmembers()
                files = [{"name": m.name, "size": m.size, "type": m.type} for m in members]
                data["files"] = files
                data["file_count"] = len(files)
                # Detect path traversal attacks
                traversals = [m.name for m in members if ".." in m.name or m.name.startswith("/")]
                if traversals:
                    data.setdefault("anomalies", []).append(
                        f"Path traversal entries detected: {traversals[:5]}"
                    )
        except Exception as exc:
            data["error"] = str(exc)
        return data


# ---------------------------------------------------------------------------
# Unified Dispatcher
# ---------------------------------------------------------------------------

class MultiFormatEngine:
    """
    Unified entry point that detects file format and dispatches to the
    appropriate format-specific analyzer.

    Usage::

        engine = MultiFormatEngine("/path/to/sample")
        result = engine.analyze()
    """

    FORMAT_ANALYZERS = {
        "elf": ELFAnalyzer,
        "macho": MachOAnalyzer,
        "dex": DEXAnalyzer,
        "ole": OLEAnalyzer,
        "pdf": PDFAnalyzer,
    }

    def __init__(self, file_path: str):
        if not os.path.isfile(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")
        self.file_path = file_path

    def analyze(self) -> Dict[str, Any]:
        """
        Detect the file format and run the appropriate analyzer.

        Returns a unified result dict with at minimum:
        ``format``, ``hashes``, ``size``, and format-specific keys.
        """
        fmt = _detect_format(self.file_path)
        logger.info("Detected format '%s' for %s", fmt, self.file_path)

        if fmt == "zip_based":
            # APK detection: look for AndroidManifest.xml in the ZIP
            try:
                with zipfile.ZipFile(self.file_path, "r") as zf:
                    if "AndroidManifest.xml" in zf.namelist():
                        fmt = "apk"
                    else:
                        fmt = "archive"
            except Exception:
                fmt = "archive"

        if fmt in ("rar", "gz", "bz2", "xz", "archive"):
            return ArchiveAnalyzer(self.file_path).analyze()

        if fmt == "apk":
            return APKAnalyzer(self.file_path).analyze()

        if fmt in self.FORMAT_ANALYZERS:
            return self.FORMAT_ANALYZERS[fmt](self.file_path).analyze()

        # Fallback: treat as firmware / unknown binary
        return FirmwareAnalyzer(self.file_path).analyze()
